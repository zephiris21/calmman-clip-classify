---
title: 얼굴없는 프레임에 대한 대처
tags:
  - 프로젝트
created: 2025-06-06 16:24:23
related_project:
  - "[[감정인식 분류모델]]"
category: sub-project
link:
---
# 침착맨 재미도 예측 프로젝트 - 추가 설계 변경사항 및 최적화 방안

## 📋 문서 개요

초기 로드맵 작성 이후 심화 논의를 통해 도출된 설계 변경사항과 최적화 방안을 정리한 문서입니다.

---

## 🎭 1. 얼굴 인식 전략 변경

### 1.1 초기 계획의 문제점

- **복잡성**: 복수 얼굴 처리 (침착맨 + 게스트)
- **일관성 부족**: 감정 주체가 불분명
- **구현 난이도**: person_id 관리, 얼굴별 가중치 설정

### 1.2 변경된 전략: 침착맨 단독 집중

```python
기존: 복수 얼굴 → 복잡한 선택 로직
변경: FaceNet 필터링 → 침착맨만 추출
```

#### **핵심 결정사항**

- **수집 기준**: 침착맨 얼굴이 80% 이상 등장하는 영상
- **필터링**: 기존 FaceNet 시스템으로 침착맨 이외 얼굴 자동 제거
- **게스트 영상**: 자동으로 "얼굴 없는 구간" 처리

#### **장점**

- 학습 복잡도 대폭 감소
- 일관된 감정 분석 주체 확보
- 향후 멀티 인물 처리로 점진적 확장 가능

#### **부수 효과**

- 게스트 영상도 "침착맨 등장 구간"만 부분적 활용 가능
- 시스템 강건성 증대

---

## ⏱️ 2. 클립 길이 및 샘플링 전략

### 2.1 클립 길이 제한 설정

#### **결정된 범위**

- **권장 범위**: 15~45초
- **핵심 타겟**: 20~30초
- **최적 길이**: 25초 (구간당 6.25초)

#### **제한 이유**

```
너무 짧음 (5-10초): 기승전결 표현 부족
적당함 (15-45초): 완전한 재미 패턴 + 쇼츠 특성 유지
너무 김 (60초+): 구간별 해상도 저하 + 집중도 분산
```

### 2.2 혁신적 아이디어: 적응적 프레임 샘플링

#### **핵심 개념**

감정 변화 속도가 다른 클립들을 **시간적 정규화**를 통해 동일한 밀도로 변환

#### **구현 방식**

```python
목표: 각 구간당 고정 프레임 수 (10프레임)
방법: 클립 길이에 따른 샘플링 간격 조정

20초 클립: 구간당 5초 → 0.5초 간격 샘플링
40초 클립: 구간당 10초 → 1.0초 간격 샘플링

결과: 모든 클립이 [4구간 × 10프레임 × 12차원] 구조로 통일
```

#### **효과**

- **빠른 전개**: 세밀한 샘플링으로 순간적 변화 포착
- **느린 전개**: 성긴 샘플링으로 전체 흐름 포착
- **정규화**: "재미의 밀도" 통일

#### **통계적 고려사항**

- **표준편차 일관성**: 충분한 샘플 수로 변동성 정확 포착
- **최소 프레임**: 구간당 8-10프레임으로 통계적 신뢰성 확보

---

## 🎵 3. 오디오 처리 방식 개선

### 3.1 기존 계획의 문제점 발견

#### **잘못된 접근법**

```python
# 문제가 있던 방식
프레임별 순간 샘플링:
프레임1: 0초 순간의 RMS
프레임2: 0.5초 순간의 RMS
→ 연속 음성의 대부분 손실!
```

#### **실제 문제 상황**

```
연속 음성: "안녕하세요 여러분!"
2fps 샘플링: "안", "여", "분" 만 포착
누락: "녕하세요 러" (70% 정보 손실)
```

### 3.2 개선된 처리 방식

#### **핵심 아이디어: 처리 단위 분리**

```python
영상 (감정 분류): 연산 부담 크다 → 프레임 스킵 필요
음성 (RMS 계산): 연산 가볍다 → 전체 데이터 활용 가능
```

#### **구현 방식**

```python
# 개선된 방식
구간별 연속 분석:
구간1 (0-0.5초): 전체 0.5초 음성의 RMS + 변화율
구간2 (0.5-1초): 전체 0.5초 음성의 RMS + 변화율

각 구간에서:
- RMS 평균 + RMS 표준편차
- 단기 변화율 평균 + 단기 변화율 표준편차
```

#### **특징 의미 분석**

- **RMS 평균**: 구간의 전체적인 음량 크기
- **RMS 표준편차**: 구간 내 음량 변동폭 (일정함 vs 들쭉날쭉함)
- **변화율 평균**: 구간의 전체적인 음량 변화 속도
- **변화율 표준편차**: 변화 패턴의 불규칙성 (예측가능 vs 갑작스러움)

---

## 🔍 4. 얼굴 없는 프레임 처리 전략

### 4.1 검토된 해결 방안들

#### **방안 1: 보간법**

```python
이전 얼굴 + 다음 얼굴의 평균으로 채움
```

**문제점**: 실제와 다른 인위적 데이터 생성

#### **방안 2: 특별 벡터 설정**

```python
얼굴 없음 = Neutral 감정으로 고정
```

**문제점**: 다양한 상황의 단순화

#### **방안 3: 해당 프레임 스킵**

```python
얼굴 있는 프레임만으로 구간별 통계 계산
```

**문제점**: 구현 복잡도 증가, 시간 정보 왜곡

#### **방안 4: 자연스러운 통계 반영**

```python
얼굴 없음 → 평균/표준편차 자동 감소
```

**치명적 문제**: 원인 모호성

- 감정 변화가 적어서 값이 낮은가?
- 얼굴 인식 실패로 값이 낮은가?

### 4.2 최종 해결책: 얼굴 인식 비율 특징 추가

#### **핵심 아이디어**

문제를 피하지 말고 **특징으로 활용**하자!

#### **구현**

```python
기존 특징:
- 감정: 20차원 × 4구간 = 80차원
- 오디오: 4차원 × 4구간 = 16차원

추가 특징:
- 얼굴 인식 비율: 1차원 × 4구간 = 4차원
  (detected_faces / total_frames_in_segment)

총합: 100차원 고정 특징 벡터
```

#### **장점**

1. **원인 구분 가능**: 감정 변화 vs 기술적 한계 명확 분리
2. **학습 효과**: 모델이 "얼굴 부재 상황"도 맥락으로 활용
3. **실용성**: "얼굴 안 보여도 재밌는 구간" 패턴 학습 가능
4. **확장성**: 게스트 영상도 부분적 처리 가능

---

## 📊 5. 최종 특징 벡터 구조

### 5.1 구간별 특징 (25차원)

```python
┌─ 감정 평균 (10차원)
│  [anger_avg, contempt_avg, disgust_avg, fear_avg, 
│   happiness_avg, neutral_avg, sadness_avg, surprise_avg,
│   valence_avg, arousal_avg]
├─ 감정 표준편차 (10차원)
│  [anger_std, contempt_std, disgust_std, fear_std,
│   happiness_std, neutral_std, sadness_std, surprise_std,
│   valence_std, arousal_std]
├─ RMS 평균 (1차원)
├─ RMS 표준편차 (1차원)
├─ 변화율 평균 (1차원)
├─ 변화율 표준편차 (1차원)
└─ 얼굴 인식 비율 (1차원)
```

### 5.2 전체 특징 벡터 (100차원)

```python
[구간1_25차원, 구간2_25차원, 구간3_25차원, 구간4_25차원]
= 25차원 × 4구간 = 100차원 고정
```

---

## 🎯 6. 실제 영상 적용시 윈도우 최적화 방안

### 6.1 현실적 한계 인식

#### **프로젝트 목표 vs 현실**

```
이상적 목표: 완벽한 재미 구간 탐지
현실적 목표: 감정적으로 활발한 구간 탐지
실용적 가치: 편집자 업무 80% → 20% 단축
```

#### **내용적 재미 vs 감정적 재미**

```
감정 기반 탐지 가능:
✅ 웃음 터지는 순간
✅ 텐션 급상승 구간  
✅ 예측 불가한 리액션

감정 기반 탐지 어려움:
❌ 언어유희, 상황적 개그
❌ 미묘한 센스, 맥락적 재미
❌ 조용하지만 중요한 순간
```

### 6.2 윈도우 최적화 전략

#### **단계별 처리 파이프라인**

```python
1단계: 텐션 사전 스캔
- Arousal + RMS 기반 빠른 스캔
- 일정 기준 이상 구간만 선별

2단계: 정밀 분류
- 선별된 구간만 100차원 특징 추출
- 재미도 분류 모델 적용
```

#### **텐션 기반 윈도우 배치**

```python
기존: 텐션 피크를 윈도우 중앙에 배치
개선: 텐션 피크를 윈도우 후반부(75% 지점)에 배치

이유: 기승전결에서 클라이맥스는 보통 끝부분
구현: 피크 - 22.5초 = 윈도우 시작점 (30초 윈도우 기준)
```

### 6.3 고도화 아이디어: 가변 구간 탐지

#### **중첩 윈도우 + 점수 맵핑**

```python
과정:
1. 20초 윈도우로 2초 간격 스캔
2. 각 윈도우별 재미도 점수 계산
3. 연속된 고점수 구간 병합

예시:
2-22초: 점수 0.8
4-24초: 점수 0.9  
6-26초: 점수 0.7
8-28초: 점수 0.8
→ 병합: 2-28초 (26초 자연 구간)
```

#### **장점과 한계**

**장점**:

- 실제 재미 지속 시간에 맞는 가변 길이
- 정확한 시작/끝점 탐지
- 고정 윈도우 대비 높은 정밀도

**한계**:

- 맥락적 설명 부분 누락 가능성
- 완전한 기승전결보다는 하이라이트 중심

---

## 🔄 7. 로드맵 업데이트

### 7.1 기존 로드맵 유지 항목

```
✅ Phase 1: 데이터 수집 (침착맨 단독 영상 20-30개)
✅ Phase 2: 오디오 추출기 구현
✅ Phase 3: VA + 오디오 통합 파이프라인 (12차원 → 100차원)
✅ Phase 4: 시각화 및 검증
```

### 7.2 추가/변경 항목

```
🆕 Phase 4.5: 텐션 기반 사전 필터링 시스템
🆕 Phase 5.5: 중첩 윈도우 점수 맵핑 시스템
🔄 Phase 6: HDF5 구조 개선 (얼굴 인식 비율 포함)
🔄 Phase 7: 100차원 특징 기반 Ridge 회귀 학습
```

### 7.3 성공 지표 조정

```
기존: 70% 재미 구간 탐지 정확도
조정: 80% 감정 하이라이트 구간 탐지 + 편집 시간 50% 단축

추가 지표:
- 텐션 곡선과 실제 재밌는 구간의 상관관계
- 가변 구간 탐지의 경계 정확도
- 실제 편집자의 사용성 평가
```

---

## 🚀 8. 향후 확장 가능성

### 8.1 단기 확장 (3-6개월)

- **멀티 스케일 윈도우**: 15초/30초/45초 동시 스캔
- **실시간 처리**: 스트리밍 중 텐션 모니터링
- **다양한 통계량**: median, quantile 등 추가 특징

### 8.2 중기 확장 (6-12개월)

- **멀티 인물 처리**: 침착맨 + 게스트 동시 분석
- **맥락 이해**: 자막, 화면 정보 추가 활용
- **장르별 특화**: 게임, 토크, 리액션별 모델

### 8.3 장기 비전 (1년+)

- **완전 자동 편집**: 재밌는 구간 자동 연결
- **개인화**: 시청자 취향별 맞춤 하이라이트
- **크로스 플랫폼**: 트위치, 아프리카TV 등 확장

---

## 📝 9. 결론 및 다음 단계

### 9.1 핵심 혁신 포인트

1. **적응적 프레임 샘플링**: 시간적 정규화를 통한 재미 밀도 통일
2. **얼굴 인식 비율 특징**: 기술적 한계를 학습 특징으로 전환
3. **텐션 기반 최적화**: 2단계 처리로 효율성과 정확도 동시 확보

### 9.2 현실적 기대치

- **100% 완벽한 재미 탐지**: 불가능
- **80% 감정 하이라이트 탐지**: 충분히 가능
- **편집 효율성 대폭 향상**: 실용적 가치 확실

### 9.3 즉시 시작할 작업

1. **오디오 추출기 구현**: RMS + 변화율 추출
2. **VA 통합**: 기존 torch_video_processor에 감정 분석 추가
3. **시각화 시스템**: Arousal 곡선으로 기본 검증

---

## 📊 10. 3단계 라벨링 시스템 도입

### 10.1 기존 이진 분류의 한계

#### **문제점**

```python
기존: 재밌음(1) vs 재미없음(0)
문제: 중간 영역의 애매한 경계
- 무난한 토크 vs 재밌는 순간 구분 어려움
- 주관적 판단의 불일치
```

### 10.2 현실적인 3단계 분류 체계

#### **라벨 구조**

```python
라벨 0 (Low/Boring): 조용한 혼자 게임
- 무언 또는 최소한의 리액션
- RMS 매우 낮음, 감정 변화 거의 없음
- 키보드/마우스 소리 위주

라벨 1 (Medium/Normal): 무난한 소통/토크
- 일반적인 대화 수준
- RMS 중간, 평이한 감정 상태
- "아 그렇구나", "흠..." 같은 평범한 반응

라벨 2 (High/Fun): 재밌는 하이라이트
- 텐션 폭발, 감정 급변
- RMS 높음, 활발한 감정 표현
- 웃음, 놀람, 흥미진진한 순간
```

### 10.3 3단계 분류의 장점

#### **현실적 분포 반영**

- 실제 침착맨 영상의 텐션 분포와 일치
- 명확한 대조군 존재 (라벨 0 vs 라벨 2)
- 애매한 중간 영역을 별도 카테고리로 분리

#### **더 정교한 모델**

```python
순서형 분류: 0 < 1 < 2 관계 학습
확률적 해석: 각 레벨별 확률 분포 제공
임계값 유연성: 상황별 기준 조정 가능
```

#### **실용적 활용**

```python
편집 가이드라인:
- 라벨 2: 무조건 포함 (핵심 하이라이트)
- 라벨 1: 맥락에 따라 포함 (연결 구간)
- 라벨 0: 일반적으로 제외 (필러)
```

### 10.4 가중치 기반 연속 재미도 점수

#### **핵심 아이디어**

3단계 분류 확률을 가중치로 변환하여 연속적 재미도 점수 생성

#### **구현 방식**

```python
가중치 설정:
라벨 0 (Boring): 가중치 0.0
라벨 1 (Normal): 가중치 0.5
라벨 2 (Fun): 가중치 1.0

점수 계산:
재미도 = (P(0) × 0.0) + (P(1) × 0.5) + (P(2) × 1.0)

예시:
확률 분포: [0.01, 0.29, 0.70]
재미도 점수: (0.01×0) + (0.29×0.5) + (0.70×1.0) = 0.845
```

#### **장점**

- **연속값 제공**: 이산적 분류 → 연속적 재미도 스코어
- **직관적 해석**: 0.8 = "꽤 재밌음", 0.3 = "그냥 그럼"
- **유연한 임계값**: 상황에 따라 0.6 이상, 0.8 이상 등 조절
- **시각화 친화적**: 재미도 곡선 그래프 생성 가능

### 10.5 3단계 분류의 단점 및 대응방안

#### **주요 단점들**

```python
복잡성 증가: 모델 구현 및 튜닝 복잡도 상승
데이터 요구량: 각 클래스별 충분한 데이터 필요 (총 1.5배)
라벨링 주관성: 특히 1 vs 2 경계의 애매함
클래스 불균형: 라벨 1이 상대적으로 적을 가능성
```

#### **대응 방안**

- **명확한 라벨링 가이드라인** 수립
- **라벨 1 데이터 의도적 수집** 강화
- **가중치 점수 활용**으로 경계 모호성 완화
- **단계적 검증**: 이진 분류 먼저 구현 후 3단계로 확장

### 10.6 텐션 사전 분류와의 관계

#### **상호 보완적 활용**

```python
1단계: Arousal + RMS 기반 텐션 사전 스캔
- 라벨 0 구간 대부분 자동 필터링
- 처리 효율성 대폭 향상

2단계: 3단계 분류 모델 적용  
- 라벨 1-2 구간의 정밀한 구분
- 단순 텐션으론 구분 어려운 미묘한 재미 탐지
```

#### **한계 인식**

```python
텐션 높음 ≠ 항상 재밌음
- 화날 때: 높은 Arousal, 하지만 재미없음
- 집중할 때: 높은 텐션, 하지만 조용함
- 당황할 때: 높은 RMS, 하지만 즐겁지 않음

→ 복합적 특징 학습이 여전히 필요
```

---

## 🔄 11. 최종 로드맵 업데이트

### 11.1 데이터 수집 전략 변경

```python
기존: 이진 분류용 40개 (재밌음/재미없음 각 20개)
변경: 3단계 분류용 60개 
- 라벨 0: 20개 (조용한 게임)
- 라벨 1: 20개 (무난한 토크)  
- 라벨 2: 20개 (재밌는 하이라이트)
```

### 11.2 모델 구조 변경

```python
기존: Ridge 회귀 (이진 분류)
변경: 다중 클래스 분류기 + 가중치 점수 변환
- Softmax 출력 → 3개 클래스 확률
- 가중치 적용 → 연속 재미도 점수 (0-1)
```

### 11.3 평가 지표 추가

```python
기존: 이진 분류 정확도
추가:
- 3클래스 분류 정확도
- 클래스별 precision/recall
- 연속 재미도 점수의 상관관계
- 실제 편집 가이드와의 일치도
```

---

## 📝 12. 결론 및 최종 다음 단계

### 12.1 핵심 설계 결정사항 요약

1. **침착맨 단독 집중**: 복잡성 최소화, 확장성 확보
2. **적응적 프레임 샘플링**: 시간적 정규화로 재미 밀도 통일
3. **얼굴 인식 비율 특징**: 기술적 한계를 학습 특징으로 전환
4. **오디오 연속 처리**: 프레임별 손실 방지
5. **3단계 라벨링**: 현실적 분포 + 가중치 기반 연속 점수
6. **텐션 기반 최적화**: 2단계 처리로 효율성과 정확도 동시 확보

### 12.2 현실적 기대치 재조정

```python
최종 목표: "편집자 업무 효율 80% 향상"

달성 방법:
- 라벨 0 구간: 자동 제외 (시간 절약)
- 라벨 2 구간: 우선 검토 (핵심 포착)  
- 라벨 1 구간: 맥락적 판단 (연결성)
- 연속 재미도: 정밀한 구간 탐지
```

### 12.3 즉시 시작할 작업 (우선순위)

1. **3단계 데이터 수집**: 명확한 가이드라인 수립
2. **오디오 추출기 구현**: RMS + 변화율 추출
3. **VA 통합 파이프라인**: 12차원 → 100차원 확장
4. **시각화 검증**: Arousal 곡선과 실제 라벨 상관관계 분석

**다음 문서**: 각 컴포넌트별 상세 구현 가이드 작성 예정



# 머신러닝 분류기
## ⚖️ XGB vs Ridge 비교 (재미도 예측)

### **예상 성능**

**XGB > Ridge** 가능성 높음

### **이유: 비선형 관계 존재**

```python
재미 패턴 예시:
- Arousal 급상승 + RMS 급상승 → 재밌음
- 감정 변화량 × 음량 변화량 → 상호작용
- 구간별 패턴 조합 (1구간 낮음 + 4구간 높음 → 기승전결)
```

### **XGB 장점** ✅

- **상호작용 학습**: 감정×오디오 조합 패턴
- **비선형 관계**: 복잡한 재미 패턴 포착
- **자동 특징 선택**: 중요한 구간/특징 자동 발견
- **과적합 방지**: 부스팅으로 안정성

### **Ridge 장점** ✅

- **해석 용이성**: 어떤 특징이 중요한지 명확
- **빠른 학습**: 데이터 적을 때 유리
- **안정성**: 노이즈에 강함

### **Ridge 한계** ❌

- **선형 가정**: 복잡한 재미 패턴 놓칠 수 있음
- **상호작용 못잡음**: 수동으로 특징 엔지니어링 필요

## 🎯 결론

**XGB 추천!** 재미도는 복잡한 비선형 패턴일 가능성 높아요.