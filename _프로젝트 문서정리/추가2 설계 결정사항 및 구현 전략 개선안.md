---
title: 추가2 설계 결정사항 및 구현 전략 개선안
tags:
  - 프로젝트
created: 2025-06-07 16:07:53
related_project:
  - "[[감정인식 분류모델]]"
category: sub-project
link:
---
📋 **추가2 설계 문서 반영 - VAD 통합 수정 계획**

문서를 검토한 결과, **핵심 설계 변경사항**을 VAD 통합에 반영해야겠네요!

## 🚨 **중요한 설계 변경 반영**

### **1. 얼굴 인식 비율 특징 완전 제거**

```python
기존 계획: RMS + VAD (2차원) → 8차원 (4구간 × 2차원)
수정 계획: RMS + VAD (2차원) → 8차원 (4구간 × 2차원) ✅ 동일

# 96차원 최종 구조 (변경 없음)
감정: 80차원 (20차원 × 4구간)  
오디오: 16차원 (4차원 × 4구간) ← VAD 포함
총합: 96차원
```

### **2. 학습 데이터 품질 관리**

```python
구간별 최소 얼굴 인식 기준: 40%

VAD와 연계한 품질 기준:
- 얼굴 비율 >= 40% (기존)
- 발화 비율 >= 20% (NEW) ← 너무 조용한 구간 제외

이유: 재밌는 순간은 보통 말을 많이 하므로
```

### **3. 3단계 라벨링 시스템 대응**

```python
라벨 0 (Boring): 혼자 게임 → VAD 매우 낮음
라벨 1 (Normal): 무난한 토크 → VAD 중간
라벨 2 (Fun): 활발한 리액션 → VAD 높음 + 변화 많음

VAD 특징이 라벨 구분에 매우 유용할 것!
```

## 🔧 **수정된 VAD 통합 계획**

### **1. 오디오 특징 구조 (4차원/구간)**

```python
각 구간별:
├─ RMS 평균 (1차원)
├─ RMS 표준편차 (1차원) 
├─ VAD 비율 (1차원) ← 발화 밀도
└─ VAD 변화 횟수 (1차원) ← 발화 패턴 변화

총 오디오 특징: 4차원 × 4구간 = 16차원
```

### **2. 데이터 품질 필터링**

```python
def is_valid_segment(emotion_data, audio_data):
    face_ratio = np.mean(emotion_data['face_detected'])
    vad_ratio = np.mean(audio_data['vad_labels'])
    
    return (face_ratio >= 0.4 and vad_ratio >= 0.2)
    
# 두 조건 모두 만족하는 클립만 학습 데이터 사용
```

### **3. HDF5 구조 확장**

```python
sequences_group:
├─ rms_values: [N]     # 기존
├─ vad_labels: [N]     # NEW: 0/1 음성활동
├─ vad_changes: [N-1]  # NEW: VAD 상태 변화 횟수  
└─ timestamps: [N]     # 기존

metadata:
├─ voice_activity_ratio: float  # 전체 발화 비율
├─ silence_periods: List        # 침묵 구간들
└─ speech_burst_count: int      # 발화 구간 개수
```

### **4. 텐션 계산 연계**

```python
# 텐션 계산에서 VAD 활용
voice_frames = rms_window[vad_window == 1]
voice_rms = np.mean(voice_frames) if len(voice_frames) > 0 else 0.0

# 발화 패턴도 텐션에 반영
vad_changes = np.sum(np.diff(vad_window.astype(int)) != 0)
pattern_bonus = min(vad_changes * 0.1, 0.3)  # 변화 많을수록 텐션 증가
```

## 🎯 **우선 구현할 VAD 기능들**

### **Phase 1: 기본 VAD 통합**

1. WebRTC VAD 라이브러리 설치
2. `audio_preprocessor.py`에 VAD 시퀀스 추출 추가
3. HDF5 저장 구조 업데이트

### **Phase 2: 품질 필터링**

1. VAD 기반 데이터 품질 체크
2. 통계 정보 확장 (발화 비율 등)
3. 시각화 도구에 VAD 정보 추가

### **Phase 3: 학습 연계**

1. 96차원 특징 추출기에 VAD 통합
2. 3단계 라벨링과 VAD 패턴 상관관계 분석
3. 텐션 계산 시스템과 연동


