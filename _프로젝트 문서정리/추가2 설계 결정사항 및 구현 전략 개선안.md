---
title: 추가2 설계 결정사항 및 구현 전략 개선안
tags:
  - 프로젝트
created: 2025-06-07 16:07:53
related_project:
  - "[[감정인식 분류모델]]"
category: sub-project
link:
---
# 설계 결정사항 및 구현 전략 개선안

## 📋 문서 개요

기존 프로젝트 계획서 검토 과정에서 발견된 핵심 이슈들과 개선된 설계 결정사항을 정리한 문서입니다.

---

## 🚨 핵심 문제 발견: 데이터 편향 이슈

### 문제 상황

```python
라벨 0 (재미없음): 게임 풀영상 → 얼굴 안정적 탐지 → face_ratio 높음
라벨 2 (재밌음): 편집된 영상 → 얼굴 불안정 탐지 → face_ratio 낮음

결과: 모델이 "얼굴 안 보이면 재밌다"고 잘못 학습할 위험
```

### 근본 원인 분석

- **편집된 영상의 특성**: 재밌는 순간에 게임 화면 확대, 자막 강조, 특수효과 등으로 얼굴 가림
- **데이터 수집 불균형**: 재미없는 구간은 풀영상, 재밌는 구간은 편집영상에서 수집
- **도메인 불일치**: 학습(편집효과 포함) vs 실제사용(풀영상, 편집효과 없음)

---

## 🎯 개선된 설계 결정사항

### 1. 얼굴 인식 비율 특징 완전 제거

#### 결정사항

```python
기존: 100차원 (얼굴 비율 포함)
변경: 96차원 (얼굴 비율 제외)

구간별 24차원:
- 감정 평균 (10차원)
- 감정 표준편차 (10차원)  
- RMS 평균/표준편차 (2차원)
- 변화율 평균/표준편차 (2차원)

총 특징: 24차원 × 4구간 = 96차원
```

#### 이유

- 편집 효과로 인한 false signal 완전 차단
- 순수한 감정/오디오 특징만으로 재미 판단
- 데이터 편향 문제 근본적 해결

### 2. 데이터 품질 관리 전략

#### 구간별 최소 얼굴 인식 기준

```python
임계값: 40% (구간별 최소 얼굴 인식 비율)

처리 방식:
- 기준 미달 구간 포함 클립 → 학습 데이터에서 제외
- 기준 통과 구간만 → 정상적인 평균/표준편차 계산
```

#### 장점

- **통계적 안정성**: 충분한 프레임으로 신뢰할 수 있는 통계 계산
- **편향 제거**: 편집 효과로 인한 노이즈 데이터 자동 필터링
- **구현 단순성**: 복잡한 보간 없이 기준 통과/실패만 판단

---

## 🏗️ 개선된 파이프라인 구조

### 3단계 분리 아키텍처

#### **1단계: HDF5 원시 데이터 수집**

```python
목적: 모든 정보를 프레임별로 상세 기록 (필터링 없음)

구조:
{
    'video_metadata': {
        'filename': str,
        'duration': float, 
        'fps': float
    },
    'frame_features': {
        'emotions': [N, 10],        # VA + 8개 감정
        'audio': [N, 2],           # RMS + 변화율  
        'timestamps': [N],         # 정확한 시간
        'face_detected': [N],      # True/False 배열
        'face_confidence': [N]     # 얼굴 인식 신뢰도 (옵션)
    }
}
```

#### **2단계: 시각화 & 탐색적 분석**

```python
목적: 원시 데이터 패턴 파악 및 가설 검증

분석 항목:
- 감정분류 비율 파이차트
- 얼굴 인식률 시간별 곡선
- VA (Valence/Arousal) 변화 추이  
- 오디오 RMS 패턴
- 감정별 시간 분포
- 전체적인 텐션 흐름

범용성: 학습용/추론용 영상 모두 동일 프로세스 적용
```

#### **3단계: 데이터셋 생성 (학습/추론 시점)**

```python
목적: 원시 데이터를 96차원 특징으로 변환

프로세스:
def create_training_sample(hdf5_data, start_time, duration):
    # 1. HDF5에서 해당 구간 추출
    segment_data = extract_time_range(hdf5_data, start_time, duration)
    
    # 2. 4구간으로 분할
    segments = split_into_4_segments(segment_data)
    
    # 3. 각 구간별 face_ratio 체크
    for segment in segments:
        face_ratio = segment['face_detected'].mean()
        if face_ratio < 0.4:
            return None  # 이 샘플 제외
    
    # 4. 모든 구간 통과시 96차원 특징 추출
    return extract_96d_features(segments)
```

---

## 🔄 범용 탐색 프로세스의 장점

### 다목적 활용 가능성

#### **학습 데이터 처리 시**

- **라벨링 가이드**: VA 곡선 보고 재밌는 구간 식별
- **품질 검증**: 얼굴 인식률 사전 체크
- **데이터 밸런스**: 텐션 분포 확인

#### **실제 추론 작업 시**

- **사전 스캔**: 텐션 높은 구간 우선 탐지
- **품질 평가**: 얼굴 인식 상태 확인
- **결과 검증**: 예측 결과와 실제 패턴 비교

#### **디버깅/검증 시**

- **실패 케이스 분석**: 모델 오류 원인 파악
- **패턴 비교**: 예측 vs 실제 VA 패턴
- **특징 중요도**: 시각적 확인

### 워크플로우 일관성

```python
범용 파이프라인: 영상 입력 → HDF5 생성 → 시각화/분석

장점:
✅ 도구 재사용성 극대화
✅ 일관된 품질 기준 적용  
✅ 경험 축적 및 노하우 공유 용이
✅ 처리 전 영상 품질 사전 체크
```

---

## 📊 구체적 구현 파라미터

### 임계값 설정

```python
구간별_최소_얼굴_비율 = 0.4 (40%)

선정 이유:
- 0.3: 너무 관대 → 편집 효과 일부 포함 가능
- 0.5: 너무 엄격 → 사용 가능한 데이터 급감  
- 0.4: 적당한 균형점

검증 방법:
- 0.3, 0.4, 0.5로 각각 실험
- 학습 성능 및 편집자 평가 상관관계 측정
```

### 특징 추출 방식

```python
각 구간에서:
detected_frames = frames[face_detected == True]

if len(detected_frames) >= min_threshold:
    emotion_mean = detected_frames.mean(axis=0)  # 10차원
    emotion_std = detected_frames.std(axis=0)    # 10차원
else:
    return None  # 해당 클립 전체 제외
```

---

## 🎯 데이터 수집 전략 개선

### 기존 문제점

```python
문제: 편집된 영상으로 학습 → 편집 효과 의존성
목적: 편집 안된 풀영상에서 재밌는 구간 탐지
→ 도메인 불일치 발생
```

### 개선 방향

```python
권장: 풀영상에서 직접 재밌는 구간 라벨링
- 침착맨 풀영상 (게임, 토크, 리액션)
- 편집 효과 없는 순수한 반응만
- face_ratio >= 0.7인 구간만 선별
- 25~30초 클립으로 추출

라벨링 기준:
✅ 침착맨의 자연스러운 큰 반응
✅ 예상치 못한 상황 + 리액션  
✅ 웃음, 놀람, 흥미진진한 순간

제외 기준:
❌ 편집 효과로 만들어진 재미
❌ 자막, 확대 등의 후처리 효과
❌ 컷 편집으로 만든 템포
```

---

## 🔍 추가 검증 방안

### 모델 성능 검증

```python
실제 편집자와의 비교:
- 같은 풀영상을 모델과 편집자가 독립적으로 분석
- 재밌다고 판단한 구간의 겹침 정도 측정
- 편집 시간 단축 효과 정량화
```

### 특징 중요도 분석

```python
# 학습 후 특징별 기여도 확인
if 편집_관련_특징_중요도 > 임계값:
    데이터_재수집_또는_특징_제거()
    
목표: 순수한 감정/오디오 패턴에만 의존하는 모델
```

---

## 📈 기대 효과

### 단기 효과

- **편향 제거**: 편집 효과에 의존하지 않는 순수한 재미 탐지
- **안정성 향상**: 충분한 얼굴 프레임으로 통계적 신뢰성 확보
- **구현 단순화**: 복잡한 보간 처리 불필요

### 장기 효과

- **일반화 성능**: 다양한 유튜버, 다양한 영상 스타일에 적용 가능
- **실용성**: 실제 편집자가 사용할 수 있는 품질
- **확장성**: 실시간 스트리밍, 자동 편집 등으로 발전 가능

---

## 🚀 다음 단계

### 즉시 구현할 항목

1. **HDF5 원시 데이터 수집 파이프라인** 구현
2. **시각화 도구** 개발 (VA 곡선, 얼굴 인식률 등)
3. **96차원 특징 추출기** 구현
4. **임계값별 성능 비교** 실험

### 검증할 항목

1. **임계값 최적화**: 0.3, 0.4, 0.5 성능 비교
2. **데이터 품질**: 실제 편집자 평가와 상관관계
3. **특징 중요도**: 각 차원별 기여도 분석

이번 개선으로 더욱 견고하고 실용적인 시스템이 될 것으로 기대됩니다!