---
title: 침착맨 재미도 예측 프로젝트 - 완전 종합 정리 (1 2)
tags:
  - 프로젝트
created: 2025-06-06 15:01:31
related_project:
  - "[[감정인식 분류모델]]"
category: sub-project
link:
---
# 침착맨 재미도 예측 프로젝트 - 완전 종합 정리 (1/2)

## 🎯 프로젝트 개요

### 최종 목표

- **1단계**: 20~50초 쇼츠에서 "재밌음/재미없음" 이진 분류기 개발
- **2단계**: 긴 영상(30분~2시간)에서 재밌는 구간 자동 탐지 및 클립 추출
- **핵심 차별화**: 재미의 **시간적 패턴(기승전결)** 학습

### 도메인 특성 분석

```python
# 몰입도 vs 재미의 본질적 차이
몰입도: 상태 기반, 시간 독립적 → 전체 평균/표준편차로 충분
재미:   이벤트 기반, 시간 의존적 → 기승전결 패턴이 핵심

# 재미 패턴 예시
"평온한 대화 → 예상치 못한 상황 → 리액션 → 웃음 터짐"
```

## 🏗️ 기술 아키텍처

### 멀티모달 특징 추출

- **시각**: EfficientNet VA-MTL → 10차원 (8개 감정 + Valence + Arousal)
- **청각**: RMS 에너지 + 음량 변화율 → 2차원
- **전처리**: MTCNN 얼굴 탐지 + 정렬 + FaceNet 침착맨 필터링

### 핵심 혁신: 표준편차 기반 4등분 압축

#### 기존 문제점

```python
# 가변 길이 처리의 한계
5초: [12차원 × 10프레임] + 패딩 4개
7초: [12차원 × 14프레임] + 패딩 0개
→ 길이별 불균형, 시간 패턴 손실
```

#### 해결책: 시간 분할 + 통계 압축

```python
# 길이 무관 88차원 고정 출력
구간1 (도입 0-25%):  [감정 10차원] → mean(10) + std(10) = 20차원
구간2 (전개 25-50%): [감정 10차원] → mean(10) + std(10) = 20차원  
구간3 (위기 50-75%): [감정 10차원] → mean(10) + std(10) = 20차원
구간4 (결말 75-100%):[감정 10차원] → mean(10) + std(10) = 20차원

오디오도 동일: 각 구간 [2차원] → mean(2) + std(2) = 4차원 × 4구간 = 16차원

최종: 80 + 16 = 96차원 (수정)
```

## 📊 데이터 전략

### 수집 계획

- **유튜브 쇼츠**: 이미 검증된 재밌는 콘텐츠
- **침착맨 단독 쇼츠**: 얼굴 인식 필터링 최적화
- **목표 규모**: 100~200개 (몰입도 연구 265개 참고)

### 3가지 실험 버전

1. **VA 간소화 (16차원)**: Valence+Arousal만 4등분 - 빠른 검증
2. **감정 전체 (96차원)**: 메인 버전 - 균형잡힌 복잡도 ⭐
3. **전체 특징 (5120차원)**: 1280차원 × 4구간 - 최대 성능

### 학습 모델

- **Ridge 회귀**: L2 정규화로 적은 데이터에 최적화
- **Cross-validation**: 과적합 방지
- **확률 출력**: 연속적 재미도 스코어 제공

## 🔄 재활용 코드 현황

### 완전 재활용 ✅

```python
# 기존 코드 그대로 활용
- va_emotion_core.py           # 10차원 감정 특징 추출
- mtcnn_wrapper.py            # 얼굴 탐지 + 정렬  
- torch_video_processor.py    # 비디오 파이프라인
- FaceNet 얼굴 인식          # 침착맨 필터링
```

### 새로 구현 📝

```python
# 추가 개발 필요
- audio_extractor.py          # RMS + 변화율 추출
- statistical_compressor.py   # 4등분 통계 압축
- funny_classifier.py         # Ridge 분류 모델
- sliding_window_detector.py  # 긴 영상 분석
```

---

# 침착맨 재미도 예측 프로젝트 - 완전 종합 정리 (2/2)

## 🎬 긴 영상 처리 파이프라인

### HDF5 전처리 구조

```python
# 프레임별 원시 특징 저장
{
    'video_metadata': {
        'filename': str, 'duration': float, 'fps': float
    },
    'frame_features': {
        'emotions': [N, 10],      # 프레임별 감정
        'audio': [N, 2],          # 프레임별 음성
        'timestamps': [N],        # 시간 정보
        'face_detected': [N]      # 얼굴 탐지 여부
    }
}
```

### 슬라이딩 윈도우 전략

```python
WINDOW_DURATION = 30  # 30초 윈도우 (쇼츠 평균)
STEP_SIZE = 5         # 5초 이동 (25초 겹침)
MIN_FACE_RATIO = 0.3  # 최소 얼굴 비율

# 처리 과정
for 30초_윈도우 in 긴영상:
    if 얼굴_비율 >= 0.3:
        특징_96차원 = 4등분_압축(윈도우)
        재미점수 = 분류기.predict(특징_96차원)
        결과_저장(시작시간, 끝시간, 점수)
```

### 클립 추출 후처리

```python
# 중복 제거 및 병합
고점수_구간들 = filter(점수 > 임계값)
병합된_클립들 = 겹치는_구간_병합(고점수_구간들)

# 최종 클립 생성
for 클립 in 병합된_클립들:
    ffmpeg_추출(원본영상, 시작시간, 끝시간)
    메타데이터_저장(점수, 얼굴비율 등)
```

## 📈 구현 로드맵

### Phase 1: 분류기 개발 (4주)

1. **Week 1**: 오디오 특징 추출기 + 4등분 압축 구현
2. **Week 2**: 유튜브 쇼츠 데이터 수집 (100~200개)
3. **Week 3**: 전처리 파이프라인 구축 + 96차원 데이터셋 생성
4. **Week 4**: Ridge 분류기 학습 + 3가지 버전 성능 비교

### Phase 2: 긴 영상 시스템 (3주)

1. **Week 5**: HDF5 전처리 시스템 구현
2. **Week 6**: 슬라이딩 윈도우 + 후처리 시스템 구현
3. **Week 7**: 전체 파이프라인 통합 + 성능 최적화

### Phase 3: 검증 및 개선 (2주)

1. **Week 8**: 실제 영상으로 검증 + 품질 평가
2. **Week 9**: 최종 튜닝 + 시각화 도구 완성

## 🎯 성공 지표

### 정량적 지표

- **분류 정확도**: 70% 이상 (100~200개 데이터)
- **처리 속도**: 1시간 영상을 10분 내 분석
- **재현율**: 실제 재밌는 구간의 80% 이상 탐지

### 정성적 지표

- **패턴 학습**: "조용한 시작 → 시끄러운 클라이맥스" 패턴 인식
- **실용성**: 편집자가 실제 사용할 수 있는 품질
- **확장성**: 다른 유튜버에게도 적용 가능한 일반화

## 🚀 확장 가능성

### 단기 확장

- **다양한 윈도우 크기**: 15초, 45초, 60초 실험
- **다른 통계량**: median, quantile 등 추가
- **앙상블 모델**: 여러 분류기 조합

### 장기 비전

- **실시간 스트리밍**: 라이브 방송 재밌는 순간 실시간 탐지
- **자동 편집**: 재밌는 구간들을 자동으로 연결해 하이라이트 영상 생성
- **멀티 플랫폼**: 트위치, 아프리카TV 등 다른 플랫폼 적용

**핵심 차별화**: 기존 연구와 달리 **"재미"라는 도메인의 시간적 특성**을 정확히 파악하고, **기승전결 패턴 학습**에 특화된 세계 최초의 시스템! 🎬✨