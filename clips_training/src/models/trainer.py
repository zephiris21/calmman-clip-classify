#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import time
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Tuple, Any
from datetime import datetime

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    roc_auc_score, confusion_matrix, classification_report
)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
current_file = Path(__file__)
project_root = current_file.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ì¬ì‚¬ìš©
from clips_training.src.utils.training_utils import TrainingUtils


class XGBoostTrainer:
    """
    XGBoost ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµê¸°
    - ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ êµ¬í˜„
    - 5-fold CV ê²€ì¦
    - í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    """
    
    def __init__(self, config_path: str = "clips_training/configs/training_config.yaml"):
        """
        XGBoost í•™ìŠµê¸° ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë° ë””ë ‰í† ë¦¬ ì„¤ì •
        self.config = TrainingUtils.load_training_config(config_path)
        self.output_dirs = TrainingUtils.setup_training_directories(self.config)
        self.logger = TrainingUtils.setup_training_logging(self.config, self.output_dirs)
        
        # ëª¨ë¸ ë° ë°ì´í„° ì´ˆê¸°í™”
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
        self.logger.info("âœ… XGBoost í•™ìŠµê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_data(self) -> Tuple[np.ndarray, np.ndarray, list]:
        """
        ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬
        
        Returns:
            Tuple: (X, y, clip_ids)
        """
        TrainingUtils.print_training_banner("ë°ì´í„° ë¡œë“œ", "dataset.h5ì—ì„œ í•™ìŠµ ë°ì´í„° ë¡œë“œ")
        
        # ë°ì´í„° ë¡œë“œ
        dataset_path = self.config['data']['dataset_path']
        target_config = self.config['data']['target_config']
        
        X, y, clip_ids, metadata = TrainingUtils.load_dataset_hdf5(dataset_path, target_config)
        
        # íŠ¹ì§•ëª… ìƒì„±
        self.feature_names = TrainingUtils.get_feature_names(target_config)
        
        # ë°ì´í„° ë¶„ì„
        analysis = TrainingUtils.analyze_dataset_info(X, y, clip_ids, self.feature_names, self.logger)
        
        TrainingUtils.print_training_completion("ë°ì´í„° ë¡œë“œ", 
                                              f"ìƒ˜í”Œ: {len(X)}, íŠ¹ì§•: {X.shape[1]}, ê· í˜•: {analysis['basic_info']['is_balanced']}")
        
        return X, y, clip_ids
    
    def split_data(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        ë°ì´í„° ë¶„í•  (train/test)
        
        Args:
            X: íŠ¹ì§• ë°°ì—´
            y: ë¼ë²¨ ë°°ì—´
        """
        TrainingUtils.print_training_banner("ë°ì´í„° ë¶„í• ", "í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì…‹ ë¶„í•  ë° ì „ì²˜ë¦¬")
        
        # ì„¤ì •ê°’ ì½ê¸°
        test_size = self.config['data']['test_size']
        random_state = self.config['data']['random_state']
        stratify = y if self.config['data']['stratify'] else None
        
        # ë°ì´í„° ë¶„í• 
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, 
            test_size=test_size,
            random_state=random_state,
            stratify=stratify
        )
        
        # ìŠ¤ì¼€ì¼ë§ (ì„¤ì •ì— ë”°ë¼)
        scaler_type = self.config['preprocessing']['scaler']
        if scaler_type != 'none':
            if scaler_type == 'standard':
                self.scaler = StandardScaler()
            else:
                self.logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¼ëŸ¬: {scaler_type}, StandardScaler ì‚¬ìš©")
                self.scaler = StandardScaler()
            
            self.X_train = self.scaler.fit_transform(self.X_train)
            self.X_test = self.scaler.transform(self.X_test)
            self.logger.info(f"âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {scaler_type}")
        
        # ë¶„í•  ê²°ê³¼ ë¡œê¹…
        train_class_counts = np.bincount(self.y_train)
        test_class_counts = np.bincount(self.y_test)
        
        self.logger.info(f"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
        self.logger.info(f"   í•™ìŠµì…‹: {len(self.X_train)}ê°œ (Boring: {train_class_counts[0]}, Funny: {train_class_counts[1]})")
        self.logger.info(f"   í…ŒìŠ¤íŠ¸ì…‹: {len(self.X_test)}ê°œ (Boring: {test_class_counts[0]}, Funny: {test_class_counts[1]})")
        
        TrainingUtils.print_training_completion("ë°ì´í„° ë¶„í• ", 
                                              f"í•™ìŠµ: {len(self.X_train)}, í…ŒìŠ¤íŠ¸: {len(self.X_test)}")
    
    def train_model(self) -> Dict[str, float]:
        """
        XGBoost ëª¨ë¸ í•™ìŠµ ë° êµì°¨ ê²€ì¦
        
        Returns:
            Dict: êµì°¨ ê²€ì¦ ê²°ê³¼
        """
        TrainingUtils.print_training_banner("ëª¨ë¸ í•™ìŠµ", "XGBoost í•™ìŠµ ë° 5-fold êµì°¨ ê²€ì¦")
        
        # XGBoost íŒŒë¼ë¯¸í„° ì„¤ì •
        xgb_params = self.config['model']['xgboost'].copy()
        xgb_params['random_state'] = self.config['model']['random_state']
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = xgb.XGBClassifier(**xgb_params)
        
        # êµì°¨ ê²€ì¦ ì„¤ì •
        cv_folds = self.config['model']['cv_folds']
        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.config['model']['random_state'])
        
        # êµì°¨ ê²€ì¦ ì‹¤í–‰
        self.logger.info(f"ğŸ”„ {cv_folds}-fold êµì°¨ ê²€ì¦ ì‹œì‘...")
        start_time = time.time()
        
        cv_scores = cross_val_score(self.model, self.X_train, self.y_train, 
                                  cv=cv, scoring='accuracy', n_jobs=-1)
        
        cv_time = time.time() - start_time
        
        # CV ê²°ê³¼ ì •ë¦¬
        cv_results = {
            'cv_mean': float(np.mean(cv_scores)),
            'cv_std': float(np.std(cv_scores)),
            'cv_scores': cv_scores.tolist(),
            'cv_time': cv_time
        }
        
        # ìµœì¢… ëª¨ë¸ í•™ìŠµ
        self.logger.info("ğŸ¯ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...")
        final_start_time = time.time()
        
        self.model.fit(self.X_train, self.y_train)
        
        final_time = time.time() - final_start_time
        cv_results['final_training_time'] = final_time
        
        # ê²°ê³¼ ë¡œê¹…
        self.logger.info(f"âœ… êµì°¨ ê²€ì¦ ì™„ë£Œ:")
        self.logger.info(f"   í‰ê·  ì •í™•ë„: {cv_results['cv_mean']:.4f} (Â±{cv_results['cv_std']:.4f})")
        self.logger.info(f"   ê°œë³„ ì ìˆ˜: {[f'{score:.4f}' for score in cv_scores]}")
        self.logger.info(f"   CV ì‹œê°„: {cv_time:.2f}ì´ˆ")
        self.logger.info(f"   ìµœì¢… í•™ìŠµ ì‹œê°„: {final_time:.2f}ì´ˆ")
        
        TrainingUtils.print_training_completion("ëª¨ë¸ í•™ìŠµ", 
                                              f"CV ì •í™•ë„: {cv_results['cv_mean']:.4f} (Â±{cv_results['cv_std']:.4f})")
        
        return cv_results
    
    def evaluate_model(self) -> Dict[str, Any]:
        """
        í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        
        Returns:
            Dict: í‰ê°€ ê²°ê³¼
        """
        TrainingUtils.print_training_banner("ëª¨ë¸ í‰ê°€", "í…ŒìŠ¤íŠ¸ ì…‹ ì„±ëŠ¥ í‰ê°€ ë° í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred = self.model.predict(self.X_test)
        y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = {
            'test_accuracy': float(accuracy_score(self.y_test, y_pred)),
            'test_precision': float(precision_score(self.y_test, y_pred)),
            'test_recall': float(recall_score(self.y_test, y_pred)),
            'test_f1': float(f1_score(self.y_test, y_pred)),
            'test_roc_auc': float(roc_auc_score(self.y_test, y_pred_proba))
        }
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(self.y_test, y_pred)
        metrics['confusion_matrix'] = cm.tolist()
        
        # í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 20ê°œ)
        feature_importance = self.model.feature_importances_
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)
        
        top_features = importance_df.head(20)
        metrics['top_features'] = {
            'names': top_features['feature'].tolist(),
            'scores': top_features['importance'].tolist()
        }
        
        # ê²°ê³¼ ë¡œê¹…
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì…‹ ì„±ëŠ¥ í‰ê°€:")
        self.logger.info(f"   ì •í™•ë„: {metrics['test_accuracy']:.4f}")
        self.logger.info(f"   ì •ë°€ë„: {metrics['test_precision']:.4f}")
        self.logger.info(f"   ì¬í˜„ìœ¨: {metrics['test_recall']:.4f}")
        self.logger.info(f"   F1-score: {metrics['test_f1']:.4f}")
        self.logger.info(f"   ROC-AUC: {metrics['test_roc_auc']:.4f}")
        
        self.logger.info(f"ğŸ¯ ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì§•:")
        for i, (name, score) in enumerate(zip(top_features['feature'][:5], top_features['importance'][:5])):
            self.logger.info(f"   {i+1}. {name}: {score:.4f}")
        
        # ë¶„ë¥˜ ë³´ê³ ì„œ
        self.logger.info(f"ğŸ“‹ ë¶„ë¥˜ ë³´ê³ ì„œ:")
        report = classification_report(self.y_test, y_pred, target_names=['Boring', 'Funny'])
        for line in report.split('\n'):
            if line.strip():
                self.logger.info(f"   {line}")
        
        TrainingUtils.print_training_completion("ëª¨ë¸ í‰ê°€", 
                                              f"ì •í™•ë„: {metrics['test_accuracy']:.4f}, F1: {metrics['test_f1']:.4f}")
        
        return metrics
    
    def save_results(self, cv_results: Dict, test_metrics: Dict) -> Dict[str, str]:
        """
        ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
        
        Args:
            cv_results: êµì°¨ ê²€ì¦ ê²°ê³¼
            test_metrics: í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§€í‘œ
            
        Returns:
            Dict: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        TrainingUtils.print_training_banner("ê²°ê³¼ ì €ì¥", "ëª¨ë¸ ë° ì„±ëŠ¥ ì§€í‘œ ì €ì¥")
        
        # ì „ì²´ ê²°ê³¼ í†µí•©
        all_metrics = {
            'cross_validation': cv_results,
            'test_performance': test_metrics,
            'model_config': self.config['model'],
            'data_config': self.config['data'],
            'timestamp': datetime.now().isoformat()
        }
        
        # ëª¨ë¸ ì €ì¥
        saved_files = TrainingUtils.save_model_artifacts(
            model=self.model,
            scaler=self.scaler,
            feature_names=self.feature_names,
            config=self.config,
            output_dirs=self.output_dirs,
            metrics=all_metrics
        )
        
        TrainingUtils.print_training_completion("ê²°ê³¼ ì €ì¥", f"{len(saved_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        
        return saved_files
    
    def run_full_pipeline(self) -> Dict[str, Any]:
        """
        ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Returns:
            Dict: ì „ì²´ ì‹¤í–‰ ê²°ê³¼
        """
        pipeline_start_time = time.time()
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            X, y, clip_ids = self.load_data()
            
            # 2. ë°ì´í„° ë¶„í• 
            self.split_data(X, y)
            
            # 3. ëª¨ë¸ í•™ìŠµ
            cv_results = self.train_model()
            
            # 4. ëª¨ë¸ í‰ê°€
            test_metrics = self.evaluate_model()
            
            # 5. ê²°ê³¼ ì €ì¥
            saved_files = self.save_results(cv_results, test_metrics)
            
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
            total_time = time.time() - pipeline_start_time
            
            final_results = {
                'success': True,
                'total_time': total_time,
                'cv_results': cv_results,
                'test_metrics': test_metrics,
                'saved_files': saved_files,
                'summary': {
                    'cv_accuracy': cv_results['cv_mean'],
                    'test_accuracy': test_metrics['test_accuracy'],
                    'test_f1': test_metrics['test_f1'],
                    'top_feature': test_metrics['top_features']['names'][0]
                }
            }
            
            self.logger.info(f"\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ì´ {total_time:.1f}ì´ˆ)")
            self.logger.info(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥ ìš”ì•½:")
            self.logger.info(f"   CV ì •í™•ë„: {cv_results['cv_mean']:.4f}")
            self.logger.info(f"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_metrics['test_accuracy']:.4f}")
            self.logger.info(f"   F1-Score: {test_metrics['test_f1']:.4f}")
            self.logger.info(f"   ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•: {test_metrics['top_features']['names'][0]}")
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            
            return {
                'success': False,
                'error': str(e),
                'total_time': time.time() - pipeline_start_time
            }


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ XGBoost ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµê¸° í…ŒìŠ¤íŠ¸")
    
    try:
        # í•™ìŠµê¸° ì´ˆê¸°í™”
        trainer = XGBoostTrainer()
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        results = trainer.run_full_pipeline()
        
        if results['success']:
            print("\nâœ… ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ ì„±ê³µ!")
            print(f"ğŸ“Š CV ì •í™•ë„: {results['cv_results']['cv_mean']:.4f}")
            print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {results['test_metrics']['test_accuracy']:.4f}")
            print(f"ğŸ† ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•: {results['test_metrics']['top_features']['names'][0]}")
        else:
            print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {results['error']}")
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()