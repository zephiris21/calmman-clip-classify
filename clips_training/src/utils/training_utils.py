#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import h5py
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime

# ğŸ¯ ê¸°ì¡´ íŒ¨í„´ ê·¸ëŒ€ë¡œ ì‚¬ìš© - í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
current_file = Path(__file__)
project_root = current_file.parent.parent.parent.parent  # clips_training/src/utils â†’ project_root
sys.path.insert(0, str(project_root))

# ê¸°ì¡´ ëª¨ë“ˆ ì¬ì‚¬ìš©
from pipeline.utils.pipeline_utils import PipelineUtils


class TrainingUtils(PipelineUtils):
    """
    í•™ìŠµìš© ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ (PipelineUtils í™•ì¥)
    - ê¸°ì¡´ PipelineUtilsì˜ ëª¨ë“  ê¸°ëŠ¥ ìƒì†
    - í•™ìŠµ íŠ¹í™” ê¸°ëŠ¥ ì¶”ê°€
    """
    
    @staticmethod
    def load_training_config(config_path: str = "clips_training/configs/training_config.yaml") -> Dict:
        """
        í•™ìŠµ ì„¤ì • íŒŒì¼ ë¡œë“œ
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ë¡œë“œëœ í•™ìŠµ ì„¤ì •
        """
        try:
            # PipelineUtilsì˜ load_config ì¬ì‚¬ìš©
            config = PipelineUtils.load_config(config_path)
            print(f"âœ… í•™ìŠµ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
            return config
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    @staticmethod
    def setup_training_directories(config: Dict) -> Dict:
        """
        í•™ìŠµìš© ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        
        Args:
            config (Dict): í•™ìŠµ ì„¤ì •
            
        Returns:
            Dict: ìƒì„±ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œë“¤
        """
        base_dir = config['output']['base_dir']
        
        dirs = {
            'base': base_dir,
            'models': os.path.join(base_dir, config['output']['models_dir']),
            'results': os.path.join(base_dir, config['output']['results_dir']),
            'logs': os.path.join(base_dir, config['output']['logs_dir'])
        }
        
        # Configë³„ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì¶”ê°€ ìƒì„±
        target_config = config['data']['target_config']
        dirs['target_models'] = os.path.join(dirs['models'], f'config{target_config}')
        
        # ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_name, dir_path in dirs.items():
            os.makedirs(dir_path, exist_ok=True)
        
        print(f"ğŸ“ í•™ìŠµìš© ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {base_dir}")
        print(f"   íƒ€ê²Ÿ ëª¨ë¸ ë””ë ‰í† ë¦¬: config{target_config}")
        return dirs
    
    @staticmethod
    def setup_training_logging(config: Dict, output_dirs: Dict) -> 'logging.Logger':
        """
        í•™ìŠµìš© ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •
        
        Args:
            config (Dict): í•™ìŠµ ì„¤ì •
            output_dirs (Dict): ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ë³´
            
        Returns:
            logging.Logger: ì„¤ì •ëœ ë¡œê±°
        """
        import logging
        
        logger = logging.getLogger('ClipsTraining')
        logger.setLevel(getattr(logging, config['logging']['level']))
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # í¬ë§¤í„° ì„¤ì •
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        if config['logging']['console_output']:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        if config['logging']['file_output']:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_filename = config['logging']['log_filename'].format(timestamp=timestamp)
            log_path = os.path.join(output_dirs['logs'], log_filename)
            
            file_handler = logging.FileHandler(log_path, encoding='utf-8')
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
            
            logger.info(f"ğŸ“„ í•™ìŠµ ë¡œê·¸ íŒŒì¼: {log_path}")
        
        return logger
    
    @staticmethod
    def load_dataset_hdf5(dataset_path: str, target_config: int = 1) -> Tuple[np.ndarray, np.ndarray, List[str], Dict]:
        """
        dataset.h5ì—ì„œ ë°ì´í„° ë¡œë“œ (ë™ì  ì°¨ì› ì§€ì›)
        
        Args:
            dataset_path (str): dataset.h5 íŒŒì¼ ê²½ë¡œ
            target_config (int): íƒ€ê²Ÿ ì„¤ì • (1, 2, 3 ì¤‘ ì„ íƒ)
            
        Returns:
            Tuple: (X, y, clip_ids, metadata)
                - X: íŠ¹ì§• ë°°ì—´ (n_samples, n_features)
                - y: ë¼ë²¨ ë°°ì—´ (n_samples,)
                - clip_ids: í´ë¦½ ID ë¦¬ìŠ¤íŠ¸
                - metadata: ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„°
        """
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_path}")
        
        try:
            with h5py.File(dataset_path, 'r') as f:
                # í˜„ì¬ ë°ì´í„° í¬ê¸° í™•ì¸
                current_size = f.attrs['current_size']
                
                # íŠ¹ì§• ë°ì´í„° ë¡œë“œ (ì‹¤ì œ ì°¨ì› ì‚¬ìš©)
                features_key = f'features_config_{target_config}'
                if features_key not in f:
                    available_configs = [key for key in f.keys() if key.startswith('features_config')]
                    raise KeyError(f"config{target_config}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì •: {available_configs}")
                
                X = f[features_key][:current_size]
                y = f['labels'][:current_size] 
                
                # í´ë¦½ ID ë¡œë“œ (ë¬¸ìì—´ ì²˜ë¦¬)
                clip_ids_raw = f['clip_ids'][:current_size]
                clip_ids = []
                for clip_id in clip_ids_raw:
                    if isinstance(clip_id, bytes):
                        clip_ids.append(clip_id.decode('utf-8'))
                    else:
                        clip_ids.append(str(clip_id))
                
                # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
                metadata = {
                    'dataset_name': f.attrs.get('dataset_name', ''),
                    'created_at': f.attrs.get('created_at', ''),
                    'version': f.attrs.get('version', ''),
                    'features': f.attrs.get('features', ''),
                    'total_samples': current_size,
                    'n_features': X.shape[1],
                    'target_config': target_config
                }
                
                # ì‹¤ì œ ì°¨ì› ì •ë³´ ì¶”ê°€
                if f'{target_config}_dimensions' in f.attrs:
                    metadata['actual_dimensions'] = f.attrs[f'{target_config}_dimensions']
                
                print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:")
                print(f"   ì„¤ì •: config{target_config}")
                print(f"   ìƒ˜í”Œ ìˆ˜: {current_size}")
                print(f"   íŠ¹ì§• ì°¨ì›: {X.shape[1]}")
                print(f"   í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y)}")
                
                return X, y, clip_ids, metadata
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    @staticmethod
    def get_feature_names(target_config: int = 1) -> List[str]:
        """
        ë™ì  íŠ¹ì§•ëª… ìƒì„± (ì‹¤ì œ ì°¨ì› ê¸°ë°˜)
        
        Args:
            target_config (int): íƒ€ê²Ÿ ì„¤ì • (1, 2, 3)
            
        Returns:
            List[str]: íŠ¹ì§•ëª… ë¦¬ìŠ¤íŠ¸
        """
        # 28ì°¨ì› ê¸°ë³¸ íŠ¹ì§• ì •ì˜ (êµ¬ê°„ë³„ ë°˜ë³µ)
        base_features = []
        
        # ê°ì • íŠ¹ì§• (20ì°¨ì›: í‰ê·  10 + í‘œì¤€í¸ì°¨ 10)
        emotions = ['anger', 'contempt', 'disgust', 'fear', 'happiness', 
                   'neutral', 'sadness', 'surprise', 'valence', 'arousal']
        for emotion in emotions:
            base_features.append(f'emotion_{emotion}_mean')
        for emotion in emotions:
            base_features.append(f'emotion_{emotion}_std')
        
        # ì˜¤ë””ì˜¤ íŠ¹ì§• (4ì°¨ì›: VAD í•„í„°ë§)
        base_features.extend([
            'voice_rms_mean',       # ë°œí™” í‰ê·  ìŒëŸ‰
            'voice_rms_max',        # ë°œí™” ìµœëŒ€ ìŒëŸ‰ (í•µì‹¬!)
            'background_rms_mean',  # ë°°ê²½ìŒ í‰ê· 
            'total_rms_std'         # ì „ì²´ ë³€ë™ì„±
        ])
        
        # VAD íŠ¹ì§• (1ì°¨ì›)
        base_features.append('vad_ratio')
        
        # í…ì…˜ íŠ¹ì§• (3ì°¨ì›)
        base_features.extend([
            'tension_mean',
            'tension_std', 
            'tension_max'
        ])
        
        # êµ¬ê°„ë³„ íŠ¹ì§•ëª… ìƒì„±
        segments = 4 if target_config == 1 else (3 if target_config == 2 else 2)
        feature_names = []
        
        for seg in range(1, segments + 1):
            for feat in base_features:
                feature_names.append(f'segment{seg}_{feat}')
        
        expected_dims = len(base_features) * segments
        print(f"âœ… íŠ¹ì§•ëª… ìƒì„± ì™„ë£Œ:")
        print(f"   config{target_config}: {segments}êµ¬ê°„ Ã— {len(base_features)}ì°¨ì› = {expected_dims}ì°¨ì›")
        
        return feature_names
    
    @staticmethod
    def get_feature_blocks(target_config: int = 1) -> Dict[str, List[int]]:
        """
        íŠ¹ì§• ë¸”ë¡ë³„ ì¸ë±ìŠ¤ ë°˜í™˜ (EDAìš©)
        
        Args:
            target_config (int): íƒ€ê²Ÿ ì„¤ì •
            
        Returns:
            Dict: ë¸”ë¡ë³„ íŠ¹ì§• ì¸ë±ìŠ¤ ë”•ì…”ë„ˆë¦¬
        """
        segments = 4 if target_config == 1 else (3 if target_config == 2 else 2)
        block_size = 28  # êµ¬ê°„ë³„ íŠ¹ì§• ìˆ˜
        
        blocks = {}
        
        for seg in range(segments):
            seg_start = seg * block_size
            
            # ê° êµ¬ê°„ë³„ ë¸”ë¡ ì¸ë±ìŠ¤
            blocks[f'segment{seg+1}_emotion'] = list(range(seg_start, seg_start + 20))
            blocks[f'segment{seg+1}_audio'] = list(range(seg_start + 20, seg_start + 24))
            blocks[f'segment{seg+1}_vad'] = [seg_start + 24]
            blocks[f'segment{seg+1}_tension'] = list(range(seg_start + 25, seg_start + 28))
        
        # ì „ì²´ ë¸”ë¡ë³„ ì¸ë±ìŠ¤ (êµ¬ê°„ í†µí•©)
        blocks['all_emotion'] = []
        blocks['all_audio'] = []
        blocks['all_vad'] = []
        blocks['all_tension'] = []
        
        for seg in range(segments):
            seg_start = seg * block_size
            blocks['all_emotion'].extend(range(seg_start, seg_start + 20))
            blocks['all_audio'].extend(range(seg_start + 20, seg_start + 24))
            blocks['all_vad'].append(seg_start + 24)
            blocks['all_tension'].extend(range(seg_start + 25, seg_start + 28))
        
        return blocks
    
    @staticmethod
    def get_key_feature_indices(feature_names: List[str], config: Dict) -> Dict[str, List[int]]:
        """
        í•µì‹¬ íŠ¹ì§•ë“¤ì˜ ì¸ë±ìŠ¤ ë°˜í™˜ (ì„¤ì • ê¸°ë°˜)
        
        Args:
            feature_names (List[str]): ì „ì²´ íŠ¹ì§•ëª… ë¦¬ìŠ¤íŠ¸
            config (Dict): í•™ìŠµ ì„¤ì •
            
        Returns:
            Dict: í•µì‹¬ íŠ¹ì§• ê·¸ë£¹ë³„ ì¸ë±ìŠ¤
        """
        key_features = config['features']['key_features']
        key_indices = {}
        
        for group_name, feature_patterns in key_features.items():
            indices = []
            for pattern in feature_patterns:
                # íŒ¨í„´ê³¼ ë§¤ì¹˜ë˜ëŠ” íŠ¹ì§• ì°¾ê¸°
                matching_indices = [i for i, name in enumerate(feature_names) 
                                  if pattern in name]
                indices.extend(matching_indices)
            
            key_indices[group_name] = sorted(list(set(indices)))  # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        
        return key_indices
    
    @staticmethod
    def analyze_dataset_info(X: np.ndarray, y: np.ndarray, clip_ids: List[str], 
                           feature_names: List[str], logger=None) -> Dict:
        """
        ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´ ë¶„ì„
        
        Args:
            X: íŠ¹ì§• ë°°ì—´
            y: ë¼ë²¨ ë°°ì—´  
            clip_ids: í´ë¦½ ID ë¦¬ìŠ¤íŠ¸
            feature_names: íŠ¹ì§•ëª… ë¦¬ìŠ¤íŠ¸
            logger: ë¡œê±° (ì„ íƒì )
            
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ í†µê³„
        n_samples, n_features = X.shape
        class_counts = np.bincount(y)
        class_ratio = class_counts[1] / (class_counts[0] + class_counts[1])
        
        # íŠ¹ì§• í†µê³„
        feature_stats = {
            'mean': np.mean(X, axis=0),
            'std': np.std(X, axis=0),
            'min': np.min(X, axis=0),
            'max': np.max(X, axis=0),
            'nan_count': np.sum(np.isnan(X), axis=0),
            'inf_count': np.sum(np.isinf(X), axis=0)
        }
        
        analysis = {
            'basic_info': {
                'n_samples': n_samples,
                'n_features': n_features,
                'class_counts': class_counts.tolist(),
                'class_ratio': class_ratio,
                'is_balanced': abs(class_ratio - 0.5) < 0.1
            },
            'feature_stats': feature_stats,
            'data_quality': {
                'has_nan': np.any(feature_stats['nan_count'] > 0),
                'has_inf': np.any(feature_stats['inf_count'] > 0),
                'features_with_zero_var': np.sum(feature_stats['std'] == 0)
            }
        }
        
        # ë¡œê¹…
        log_func = logger.info if logger else print
        log_func(f"ğŸ“Š ë°ì´í„°ì…‹ ê¸°ë³¸ ë¶„ì„:")
        log_func(f"   ìƒ˜í”Œ ìˆ˜: {n_samples} (Boring: {class_counts[0]}, Funny: {class_counts[1]})")
        log_func(f"   íŠ¹ì§• ìˆ˜: {n_features}")
        log_func(f"   í´ë˜ìŠ¤ ê· í˜•: {'âœ…' if analysis['basic_info']['is_balanced'] else 'âš ï¸'} (Funny ë¹„ìœ¨: {class_ratio:.1%})")
        
        if analysis['data_quality']['has_nan']:
            log_func(f"   âš ï¸ NaN ê°’ ë°œê²¬")
        if analysis['data_quality']['has_inf']:
            log_func(f"   âš ï¸ Inf ê°’ ë°œê²¬") 
        if analysis['data_quality']['features_with_zero_var'] > 0:
            log_func(f"   âš ï¸ ë¶„ì‚°ì´ 0ì¸ íŠ¹ì§•: {analysis['data_quality']['features_with_zero_var']}ê°œ")
        
        return analysis
    
    @staticmethod
    def save_model_artifacts(model, scaler, feature_names: List[str], 
                           config: Dict, output_dirs: Dict, 
                           metrics: Dict = None) -> Dict:
        """
        ëª¨ë¸ ë° ê´€ë ¨ íŒŒì¼ë“¤ ì €ì¥
        
        Args:
            model: í•™ìŠµëœ ëª¨ë¸
            scaler: ì „ì²˜ë¦¬ ìŠ¤ì¼€ì¼ëŸ¬
            feature_names: íŠ¹ì§•ëª… ë¦¬ìŠ¤íŠ¸
            config: í•™ìŠµ ì„¤ì •
            output_dirs: ì¶œë ¥ ë””ë ‰í† ë¦¬
            metrics: ì„±ëŠ¥ ì§€í‘œ (ì„ íƒì )
            
        Returns:
            Dict: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        import pickle
        import json
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        target_config = config['data']['target_config']
        
        saved_files = {}
        
        # ëª¨ë¸ ì €ì¥
        if config['output']['save_model']:
            model_filename = f"xgboost_config{target_config}_{timestamp}.pkl"
            model_path = os.path.join(output_dirs['target_models'], model_filename)
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
            saved_files['model'] = model_path
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥  
        if config['output']['save_scaler'] and scaler is not None:
            scaler_filename = f"scaler_config{target_config}_{timestamp}.pkl"
            scaler_path = os.path.join(output_dirs['target_models'], scaler_filename)
            with open(scaler_path, 'wb') as f:
                pickle.dump(scaler, f)
            saved_files['scaler'] = scaler_path
        
        # íŠ¹ì§•ëª… ì €ì¥
        if config['output']['save_feature_names']:
            features_filename = f"feature_names_config{target_config}_{timestamp}.json"
            features_path = os.path.join(output_dirs['target_models'], features_filename)
            with open(features_path, 'w', encoding='utf-8') as f:
                json.dump(feature_names, f, ensure_ascii=False, indent=2)
            saved_files['feature_names'] = features_path
        
        # ì„±ëŠ¥ ì§€í‘œ ì €ì¥
        if config['output']['save_metrics'] and metrics:
            metrics_filename = f"metrics_config{target_config}_{timestamp}.json"
            metrics_path = os.path.join(output_dirs['results'], metrics_filename)
            with open(metrics_path, 'w', encoding='utf-8') as f:
                json.dump(metrics, f, ensure_ascii=False, indent=2)
            saved_files['metrics'] = metrics_path
        
        print(f"ğŸ’¾ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ:")
        for artifact_type, file_path in saved_files.items():
            print(f"   {artifact_type}: {file_path}")
        
        return saved_files
    
    @staticmethod
    def print_training_banner(step_name: str, description: str):
        """
        í•™ìŠµ ë‹¨ê³„ë³„ ë°°ë„ˆ ì¶œë ¥ (PipelineUtils ìŠ¤íƒ€ì¼)
        
        Args:
            step_name (str): ë‹¨ê³„ ì´ë¦„
            description (str): ë‹¨ê³„ ì„¤ëª…
        """
        print(f"\n{'='*60}")
        print(f"ğŸ¤– {step_name}")
        print(f"ğŸ“‹ {description}")
        print(f"{'='*60}")
    
    @staticmethod
    def print_training_completion(step_name: str, result_info: str = ""):
        """
        í•™ìŠµ ë‹¨ê³„ ì™„ë£Œ ë°°ë„ˆ ì¶œë ¥
        
        Args:
            step_name (str): ë‹¨ê³„ ì´ë¦„
            result_info (str): ê²°ê³¼ ì •ë³´
        """
        print(f"\nâœ… {step_name} ì™„ë£Œ!")
        if result_info:
            print(f"ğŸ“Š {result_info}")


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        # ì„¤ì • ë¡œë“œ í…ŒìŠ¤íŠ¸
        config = TrainingUtils.load_training_config()
        print("âœ… í•™ìŠµ ì„¤ì • ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸
        output_dirs = TrainingUtils.setup_training_directories(config)
        print("âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        
        # íŠ¹ì§•ëª… ìƒì„± í…ŒìŠ¤íŠ¸
        feature_names = TrainingUtils.get_feature_names(target_config=1)
        print(f"âœ… íŠ¹ì§•ëª… ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(feature_names)}ê°œ íŠ¹ì§•")
        
        # íŠ¹ì§• ë¸”ë¡ í…ŒìŠ¤íŠ¸
        blocks = TrainingUtils.get_feature_blocks(target_config=1)
        print(f"âœ… íŠ¹ì§• ë¸”ë¡ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(blocks)}ê°œ ë¸”ë¡")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()