#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.gridspec import GridSpec
from PIL import Image
import glob
from datetime import timedelta
from typing import Dict, List, Optional, Tuple
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
plt.rcParams['font.family'] = ['DejaVu Sans', 'Malgun Gothic']
plt.rcParams['axes.unicode_minus'] = False

class TensionVisualizer:
    """
    í…ì…˜ ë¶„ì„ ê²°ê³¼ ì‹œê°í™” í´ë˜ìŠ¤
    ì£¼í”¼í„°ë©ì—ì„œ ì…€ ë‹¨ìœ„ë¡œ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„
    """
    
    def __init__(self, debug_faces_dir: str = "video_analyzer/preprocessed_data/debug_faces/chimchakman"):
        """
        ì‹œê°í™” ë„êµ¬ ì´ˆê¸°í™”
        
        Args:
            debug_faces_dir (str): ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.debug_faces_dir = debug_faces_dir
        self.tension_data = None
        self.video_name = None
        
        # ê°ì • ë ˆì´ë¸” ë° ìƒ‰ìƒ
        self.emotion_labels = [
            'Anger', 'Contempt', 'Disgust', 'Fear', 
            'Happiness', 'Neutral', 'Sadness', 'Surprise'
        ]
        
        # ê°ì •ë³„ ìƒ‰ìƒ (matplotlib ê¸°ë³¸ íŒ”ë ˆíŠ¸)
        self.emotion_colors = [
            '#ff4444',  # Anger - ë¹¨ê°•
            '#8B4513',  # Contempt - ê°ˆìƒ‰  
            '#32CD32',  # Disgust - ë…¹ìƒ‰
            '#9370DB',  # Fear - ë³´ë¼
            '#FFD700',  # Happiness - ë…¸ë‘
            '#808080',  # Neutral - íšŒìƒ‰
            '#4169E1',  # Sadness - íŒŒë‘
            '#FF8C00'   # Surprise - ì£¼í™©
        ]
        
        print(f"âœ… TensionVisualizer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì–¼êµ´ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {debug_faces_dir}")
    
    def load_tension_data(self, json_file_path: str) -> bool:
        """
        í…ì…˜ ë¶„ì„ JSON ê²°ê³¼ ë¡œë“œ
        
        Args:
            json_file_path (str): JSON íŒŒì¼ ê²½ë¡œ ë˜ëŠ” íŒ¨í„´
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
            if not os.path.exists(json_file_path):
                # tension_analyzer/outputs/tension_data/ ì—ì„œ íŒ¨í„´ ê²€ìƒ‰
                search_dir = "tension_analyzer/outputs/tension_data"
                if os.path.exists(search_dir):
                    pattern = os.path.join(search_dir, f"*{json_file_path}*.json")
                    files = glob.glob(pattern)
                    if files:
                        json_file_path = files[0]  # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ì‚¬ìš©
                        print(f"ğŸ“‚ íŒ¨í„´ ë§¤ì¹­ íŒŒì¼ ë°œê²¬: {os.path.basename(json_file_path)}")
                    else:
                        print(f"âŒ íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {json_file_path}")
                        return False
                else:
                    print(f"âŒ í…ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ: {search_dir}")
                    return False
            
            # JSON ë¡œë“œ
            with open(json_file_path, 'r', encoding='utf-8') as f:
                self.tension_data = json.load(f)
            
            self.video_name = self.tension_data['metadata']['video_name']
            
            print(f"âœ… í…ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print(f"   ì˜ìƒëª…: {self.video_name}")
            print(f"   ì§€ì†ì‹œê°„: {self.tension_data['metadata']['duration']:.1f}ì´ˆ")
            print(f"   í…ì…˜ í¬ì¸íŠ¸: {len(self.tension_data['tension_timeline']['timestamps'])}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ í…ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def plot_tension_curves(self, figsize: Tuple[int, int] = (15, 10)) -> None:
        """
        3ê°€ì§€ í…ì…˜ ê³¡ì„  ì‹œê°í™”
        
        Args:
            figsize: ê·¸ë˜í”„ í¬ê¸°
        """
        if self.tension_data is None:
            print("âŒ í…ì…˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_tension_data()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
            return
        
        timeline = self.tension_data['tension_timeline']
        timestamps = np.array(timeline['timestamps'])
        emotion_tension = np.array(timeline['emotion_tension'])
        audio_tension = np.array(timeline['audio_tension'])
        combined_tension = np.array(timeline['combined_tension'])
        
        # ì‹œê°„ì„ ë¶„:ì´ˆ í˜•íƒœë¡œ ë³€í™˜
        time_labels = [str(timedelta(seconds=int(t))) for t in timestamps[::len(timestamps)//10]]
        time_indices = np.linspace(0, len(timestamps)-1, len(time_labels), dtype=int)
        
        fig, axes = plt.subplots(3, 1, figsize=figsize, sharex=True)
        fig.suptitle(f'í…ì…˜ ë¶„ì„ ê²°ê³¼: {self.video_name}', fontsize=16, fontweight='bold')
        
        # 1. ê°ì • í…ì…˜
        axes[0].plot(timestamps, emotion_tension, color='#ff6b6b', linewidth=2, label='Emotion Tension')
        axes[0].fill_between(timestamps, emotion_tension, alpha=0.3, color='#ff6b6b')
        axes[0].set_ylabel('ê°ì • í…ì…˜', fontsize=12)
        axes[0].set_title('ê°ì • ê¸°ë°˜ í…ì…˜ (ì¤‘ë¦½ ì œì™¸ 7ê°ì • + ArousalÃ—10)', fontsize=11)
        axes[0].grid(True, alpha=0.3)
        axes[0].legend()
        
        # 2. ì˜¤ë””ì˜¤ í…ì…˜
        axes[1].plot(timestamps, audio_tension, color='#4ecdc4', linewidth=2, label='Audio Tension')
        axes[1].fill_between(timestamps, audio_tension, alpha=0.3, color='#4ecdc4')
        axes[1].set_ylabel('ì˜¤ë””ì˜¤ í…ì…˜', fontsize=12)
        axes[1].set_title('ìŒì„± ê¸°ë°˜ í…ì…˜ (VAD í•„í„°ë§ëœ Voice RMS)', fontsize=11)
        axes[1].grid(True, alpha=0.3)
        axes[1].legend()
        
        # 3. ê²°í•© í…ì…˜ + í•˜ì´ë¼ì´íŠ¸ í‘œì‹œ
        axes[2].plot(timestamps, combined_tension, color='#45b7d1', linewidth=2, label='Combined Tension')
        axes[2].fill_between(timestamps, combined_tension, alpha=0.3, color='#45b7d1')
        
        # í•˜ì´ë¼ì´íŠ¸ í¬ì¸íŠ¸ í‘œì‹œ
        highlights = self.tension_data['edit_suggestions']['highlights']
        if highlights:
            highlight_times = [h['timestamp'] for h in highlights]
            highlight_tensions = [h['tension'] for h in highlights]
            axes[2].scatter(highlight_times, highlight_tensions, 
                          color='red', s=100, zorder=5, label=f'Highlights ({len(highlights)}ê°œ)')
        
        axes[2].set_ylabel('ê²°í•© í…ì…˜', fontsize=12)
        axes[2].set_xlabel('ì‹œê°„', fontsize=12)
        axes[2].set_title('ê²°í•© í…ì…˜ (ê°ì • 70% + ì˜¤ë””ì˜¤ 30%) + í•˜ì´ë¼ì´íŠ¸', fontsize=11)
        axes[2].grid(True, alpha=0.3)
        axes[2].legend()
        
        # Xì¶• ì‹œê°„ ë¼ë²¨ ì„¤ì •
        axes[2].set_xticks(timestamps[time_indices])
        axes[2].set_xticklabels(time_labels, rotation=45)
        
        plt.tight_layout()
        plt.show()
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        stats = self.tension_data['statistics']
        print(f"\nğŸ“Š í…ì…˜ í†µê³„:")
        print(f"   í‰ê· : {stats['avg_tension']:.2f}")
        print(f"   ìµœëŒ€: {stats['max_tension']:.2f}")
        print(f"   ìµœì†Œ: {stats['min_tension']:.2f}")
        print(f"   í‘œì¤€í¸ì°¨: {stats['std_tension']:.2f}")
        print(f"   ìŒì„± í™œë™ ë¹„ìœ¨: {stats['voice_activity_ratio']:.1%}")
    
    def plot_emotion_pie_chart(self, figsize: Tuple[int, int] = (12, 8)) -> None:
        """
        ê°ì • ë¶„í¬ íŒŒì´ì°¨íŠ¸ ì‹œê°í™”
        HDF5ì—ì„œ ê°ì • ë°ì´í„°ë¥¼ ë¡œë“œí•´ì„œ í†µê³„ ê³„ì‚°
        """
        if self.tension_data is None:
            print("âŒ í…ì…˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # HDF5ì—ì„œ ê°ì • ë°ì´í„° ë¡œë“œ ì‹œë„
        try:
            video_h5_path = self._find_video_h5_file()
            if video_h5_path is None:
                print("âŒ ë¹„ë””ì˜¤ HDF5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            import h5py
            with h5py.File(video_h5_path, 'r') as f:
                emotions = f['sequences/emotions'][:]  # [N, 10]
                face_detected = f['sequences/face_detected'][:]
            
            print(f"âœ… ê°ì • ë°ì´í„° ë¡œë“œ: {emotions.shape}")
            
        except Exception as e:
            print(f"âŒ ê°ì • ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # ì–¼êµ´ì´ íƒì§€ëœ í”„ë ˆì„ë§Œ ì‚¬ìš©
        valid_emotions = emotions[face_detected == True]
        if len(valid_emotions) == 0:
            print("âŒ ìœ íš¨í•œ ê°ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 8ê°œ ê°ì •ë³„ë¡œ ì–‘ìˆ˜ê°’ë§Œ í•„í„°ë§í•´ì„œ í‰ê·  ê³„ì‚°
        emotion_means = []
        for i in range(8):
            emotion_values = valid_emotions[:, i]
            positive_values = emotion_values[emotion_values > 0]  # ì–‘ìˆ˜ë§Œ í•„í„°ë§
            
            if len(positive_values) > 0:
                emotion_mean = np.mean(positive_values)
            else:
                emotion_mean = 0.0  # ì–‘ìˆ˜ê°’ì´ ì—†ìœ¼ë©´ 0
            
            emotion_means.append(emotion_mean)
            
            # ê° ê°ì •ë³„ í†µê³„ ì¶œë ¥ (ë””ë²„ê¹…)
            print(f"   {self.emotion_labels[i]}: ì „ì²´ {len(emotion_values)}ê°œ, ì–‘ìˆ˜ {len(positive_values)}ê°œ, í‰ê·  {emotion_mean:.4f}")
        
        emotion_means = np.array(emotion_means)
        
        # ì›ì‹œ ê°’ í™•ì¸ì„ ìœ„í•œ ë¡œê¹…
        print(f"ğŸ“Š ì–‘ìˆ˜ê°’ë§Œ í•„í„°ë§í•œ ê°ì • í‰ê· ê°’: {emotion_means}")
        print(f"   ë°ì´í„° ë²”ìœ„: ìµœì†Œ {np.min(emotion_means):.3f}, ìµœëŒ€ {np.max(emotion_means):.3f}")
        
        # ì´í•©ì´ 0ì´ë©´ ê· ë“± ë¶„í¬ë¡œ ì²˜ë¦¬
        if np.sum(emotion_means) == 0:
            emotion_means = np.ones(8) / 8
            print("âš ï¸ ëª¨ë“  ê°ì •ì˜ ì–‘ìˆ˜ê°’ì´ ì—†ì–´ ê· ë“± ë¶„í¬ë¡œ ì„¤ì •")
        
        # ì´í•©ì´ 0ì´ë©´ ê· ë“± ë¶„í¬ë¡œ ì²˜ë¦¬
        if np.sum(emotion_means) == 0:
            emotion_means = np.ones(8) / 8
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)
        fig.suptitle(f'ê°ì • ë¶„ì„: {self.video_name}', fontsize=16, fontweight='bold')
        
        # 1. íŒŒì´ì°¨íŠ¸
        wedges, texts, autotexts = ax1.pie(emotion_means, labels=self.emotion_labels, 
                                          colors=self.emotion_colors, autopct='%1.1f%%',
                                          startangle=90, textprops={'fontsize': 10})
        ax1.set_title('ê°ì • ë¶„í¬ (ì–¼êµ´ íƒì§€ëœ í”„ë ˆì„ ê¸°ì¤€)', fontsize=12)
        
        # 2. ë§‰ëŒ€ ê·¸ë˜í”„
        bars = ax2.bar(self.emotion_labels, emotion_means, color=self.emotion_colors, alpha=0.7)
        ax2.set_title('ê°ì •ë³„ í‰ê·  ê°•ë„', fontsize=12)
        ax2.set_ylabel('í‰ê·  ê°ì • ê°’', fontsize=11)
        ax2.tick_params(axis='x', rotation=45)
        
        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar, value in zip(bars, emotion_means):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        plt.show()
        
        # ìƒìœ„ 3ê°œ ê°ì • ì¶œë ¥
        top_emotions = np.argsort(emotion_means)[-3:][::-1]
        print(f"\nğŸ­ ì£¼ìš” ê°ì •:")
        for i, idx in enumerate(top_emotions, 1):
            print(f"   {i}. {self.emotion_labels[idx]}: {emotion_means[idx]:.3f}")
    
    def show_emotion_peak_faces(self, top_n: int = 1, figsize: Tuple[int, int] = (16, 10)) -> None:
        """
        ê°ì •ë³„ í”¼í¬ ì‹œì ì˜ ì‹¤ì œ ì–¼êµ´ ì´ë¯¸ì§€ í‘œì‹œ (ê¹”ë”í•œ subplot ë²„ì „)
        
        Args:
            top_n: ê° ê°ì •ë³„ë¡œ í‘œì‹œí•  ìƒìœ„ Nê°œ (ê¸°ë³¸ê°’ 1)
            figsize: ì „ì²´ ê·¸ë˜í”„ í¬ê¸°
        """
        if self.tension_data is None:
            print("âŒ í…ì…˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        try:
            # HDF5ì—ì„œ ê°ì • ë°ì´í„° ë¡œë“œ
            video_h5_path = self._find_video_h5_file()
            if video_h5_path is None:
                return
            
            import h5py
            with h5py.File(video_h5_path, 'r') as f:
                emotions = f['sequences/emotions'][:]  # [N, 10]
                face_detected = f['sequences/face_detected'][:]
                timestamps = f['sequences/timestamps'][:]
            
            print(f"âœ… ê°ì • ë°ì´í„° ë¡œë“œ: {emotions.shape}")
            
        except Exception as e:
            print(f"âŒ ê°ì • ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # ìœ íš¨í•œ í”„ë ˆì„ë§Œ í•„í„°ë§
        valid_mask = face_detected == True
        valid_emotions = emotions[valid_mask]
        valid_timestamps = timestamps[valid_mask]
        
        if len(valid_emotions) == 0:
            print("âŒ ìœ íš¨í•œ ê°ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í”¼í¬ ë°ì´í„° ìˆ˜ì§‘ (7ê°œ ê°ì • + Valence + Arousal)
        peak_data = []
        
        # 7ê°œ ê°ì • (Neutral ì œì™¸)
        for i, emotion_name in enumerate(self.emotion_labels):
            if emotion_name == 'Neutral':
                continue
                
            emotion_values = valid_emotions[:, i]
            emotion_values = np.maximum(emotion_values, 0)  # ì–‘ìˆ˜ë§Œ
            
            if np.max(emotion_values) > 0:
                peak_idx = np.argmax(emotion_values)
                peak_data.append({
                    'name': emotion_name,
                    'timestamp': valid_timestamps[peak_idx],
                    'value': emotion_values[peak_idx],
                    'type': 'emotion'
                })
        
        # Valence (8ë²ˆ ì¸ë±ìŠ¤)
        valence_values = valid_emotions[:, 8]
        if len(valence_values) > 0:
            # ValenceëŠ” ì ˆëŒ“ê°’ì´ í° ê²ƒ (ê·¹ê°’)
            abs_valence = np.abs(valence_values)
            peak_idx = np.argmax(abs_valence)
            peak_data.append({
                'name': 'Valence',
                'timestamp': valid_timestamps[peak_idx],
                'value': valence_values[peak_idx],
                'type': 'va'
            })
        
        # Arousal (9ë²ˆ ì¸ë±ìŠ¤)
        arousal_values = valid_emotions[:, 9]
        if len(arousal_values) > 0:
            peak_idx = np.argmax(arousal_values)
            peak_data.append({
                'name': 'Arousal',
                'timestamp': valid_timestamps[peak_idx],
                'value': arousal_values[peak_idx],
                'type': 'va'
            })
        
        if not peak_data:
            print("âŒ í‘œì‹œí•  ê°ì • í”¼í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3x3 ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜ (ìµœëŒ€ 9ê°œ)
        fig, axes = plt.subplots(3, 3, figsize=figsize)
        fig.suptitle(f'ê°ì •ë³„ í”¼í¬ ìˆœê°„ì˜ ì‹¤ì œ ì–¼êµ´: {self.video_name}', fontsize=16, fontweight='bold', y=0.99)
        
        # axesë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        axes_flat = axes.flatten()
        
        for i, peak in enumerate(peak_data[:9]):  # ìµœëŒ€ 9ê°œë§Œ í‘œì‹œ
            ax = axes_flat[i]
            
            # í•´ë‹¹ ì‹œì ì˜ ì–¼êµ´ ì´ë¯¸ì§€ ì°¾ê¸°
            face_image = self._find_face_image_at_time(peak['timestamp'])
            
            if face_image is not None:
                ax.imshow(face_image)
                
                # ì œëª© ì„¤ì • (ê°ì •ë³„ ìƒ‰ìƒ)
                color = self.emotion_colors[self.emotion_labels.index(peak['name'])] if peak['name'] in self.emotion_labels else '#333333'
                
                time_str = str(timedelta(seconds=int(peak['timestamp'])))
                if peak['type'] == 'va':
                    title = f"{peak['name']}\n{time_str}\nê°’: {peak['value']:.3f}"
                else:
                    title = f"{peak['name']}\n{time_str}\nê°’: {peak['value']:.3f}"
                    
                ax.set_title(title, fontsize=11, fontweight='bold', color=color, pad=10)
            else:
                # ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë°•ìŠ¤
                ax.set_facecolor('#f5f5f5')
                time_str = str(timedelta(seconds=int(peak['timestamp'])))
                ax.text(0.5, 0.5, f"{peak['name']}\n{time_str}\nì´ë¯¸ì§€ ì—†ìŒ", 
                       ha='center', va='center', transform=ax.transAxes, 
                       fontsize=10, color='#666666')
            
            ax.axis('off')
        
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” subplot ìˆ¨ê¸°ê¸°
        for i in range(len(peak_data), 9):
            axes_flat[i].axis('off')
        
        # ì—¬ë°± ì¡°ì • (ê²¹ì¹¨ ë°©ì§€)
        plt.subplots_adjust(top=0.88, bottom=0.05, left=0.05, right=0.95, hspace=0.5, wspace=0.2)
        plt.show()
        
        print(f"ğŸ­ ê°ì • í”¼í¬ í‘œì‹œ ì™„ë£Œ ({len(peak_data)}ê°œ: 7ê°ì • + VA)")
    
    def _find_video_h5_file(self) -> Optional[str]:
        """ë¹„ë””ì˜¤ HDF5 íŒŒì¼ ì°¾ê¸°"""
        if self.video_name is None:
            return None
        
        video_sequences_dir = "video_analyzer/preprocessed_data/video_sequences"
        if not os.path.exists(video_sequences_dir):
            return None
        
        # ë¹„ë””ì˜¤ëª…ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
        for file in os.listdir(video_sequences_dir):
            if self.video_name.replace('.mp4', '') in file and file.endswith('.h5'):
                return os.path.join(video_sequences_dir, file)
        
        return None
    
    def _auto_detect_face_dir(self) -> bool:
        """HDF5ì—ì„œ ì–¼êµ´ í´ë” ê²½ë¡œ ìë™ ê°ì§€"""
        try:
            video_h5_path = self._find_video_h5_file()
            if video_h5_path is None:
                return False
            
            import h5py
            with h5py.File(video_h5_path, 'r') as f:
                # HDF5ì— ì €ì¥ëœ ì–¼êµ´ í´ë” ê²½ë¡œ ì½ê¸°
                if 'chimchakman_faces_dir' in f.attrs:
                    auto_detected_dir = f.attrs['chimchakman_faces_dir']
                    if isinstance(auto_detected_dir, bytes):
                        auto_detected_dir = auto_detected_dir.decode('utf-8')
                    
                    if os.path.exists(auto_detected_dir):
                        self.debug_faces_dir = auto_detected_dir
                        print(f"âœ… HDF5ì—ì„œ ì–¼êµ´ í´ë” ìë™ ê°ì§€: {auto_detected_dir}")
                        return True
                    else:
                        print(f"âš ï¸ HDF5 ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {auto_detected_dir}")
                
                # ëŒ€ì•ˆ: face_images_dirì—ì„œ chimchakman í•˜ìœ„ í´ë” ì°¾ê¸°
                elif 'face_images_dir' in f.attrs:
                    base_face_dir = f.attrs['face_images_dir']
                    if isinstance(base_face_dir, bytes):
                        base_face_dir = base_face_dir.decode('utf-8')
                    
                    chimchakman_dir = os.path.join(base_face_dir, "chimchakman")
                    if os.path.exists(chimchakman_dir):
                        self.debug_faces_dir = chimchakman_dir
                        print(f"âœ… HDF5ì—ì„œ ì–¼êµ´ í´ë” ìë™ êµ¬ì„±: {chimchakman_dir}")
                        return True
                
                print("âš ï¸ HDF5ì— ì–¼êµ´ í´ë” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            print(f"âš ï¸ ì–¼êµ´ í´ë” ìë™ ê°ì§€ ì‹¤íŒ¨: {e}")
            return False
    
    def _find_face_image_at_time(self, timestamp: float) -> Optional[np.ndarray]:
        """íŠ¹ì • ì‹œê°„ì˜ ì–¼êµ´ ì´ë¯¸ì§€ ì°¾ê¸° (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)"""
        # ë¨¼ì € HDF5ì—ì„œ ì–¼êµ´ í´ë” ìë™ ê°ì§€ ì‹œë„
        if not os.path.exists(self.debug_faces_dir):
            if not self._auto_detect_face_dir():
                return None
        
        if not os.path.exists(self.debug_faces_dir):
            return None
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜ (15.750ì´ˆ â†’ 015750)
        timestamp_ms = int(timestamp * 1000)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª… íŒ¨í„´
        timestamp_pattern = f"timestamp_{timestamp_ms:06d}_face0_chimchakman_*.jpg"
        
        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        search_pattern = os.path.join(self.debug_faces_dir, timestamp_pattern)
        matching_files = glob.glob(search_pattern)
        
        if matching_files:
            try:
                image = Image.open(matching_files[0])
                return np.array(image)
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {matching_files[0]} - {e}")
        
        # ì •í™•í•œ ë§¤ì¹­ì´ ì•ˆë˜ë©´ ì£¼ë³€ ì‹œê°„ ê²€ìƒ‰ (Â±0.25ì´ˆ = Â±250ms)
        for offset_ms in [-250, -125, 125, 250]:
            alt_timestamp_ms = timestamp_ms + offset_ms
            if alt_timestamp_ms >= 0:
                alt_pattern = f"timestamp_{alt_timestamp_ms:06d}_face0_chimchakman_*.jpg"
                alt_search = os.path.join(self.debug_faces_dir, alt_pattern)
                alt_files = glob.glob(alt_search)
                
                if alt_files:
                    try:
                        image = Image.open(alt_files[0])
                        return np.array(image)
                    except Exception:
                        continue
        
        return None
    
    def auto_find_faces_dir(self, video_name: str = None) -> bool:
        """
        ì˜ìƒëª… ê¸°ë°˜ ì–¼êµ´ í´ë” ìë™ íƒì§€ (ê³µê°œ ë©”ì„œë“œ)
        
        Args:
            video_name (str): ì˜ìƒëª… (ì˜µì…˜, ì—†ìœ¼ë©´ í˜„ì¬ ë¡œë“œëœ ì˜ìƒëª… ì‚¬ìš©)
            
        Returns:
            bool: íƒì§€ ì„±ê³µ ì—¬ë¶€
        """
        if video_name:
            self.video_name = video_name
        
        if self.video_name is None:
            print("âŒ ì˜ìƒëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        return self._auto_detect_face_dir()
    
    def show_summary(self) -> None:
        """ì „ì²´ ë¶„ì„ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
        if self.tension_data is None:
            print("âŒ í…ì…˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print("="*60)
        print(f"ğŸ“Š í…ì…˜ ë¶„ì„ ìš”ì•½: {self.video_name}")
        print("="*60)
        
        stats = self.tension_data['statistics']
        print(f"ğŸ¬ ê¸°ë³¸ ì •ë³´:")
        print(f"   ì˜ìƒ ê¸¸ì´: {self.tension_data['metadata']['duration']:.1f}ì´ˆ")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {self.tension_data['metadata']['processed_at']}")
        
        print(f"\nâš¡ í…ì…˜ í†µê³„:")
        print(f"   í‰ê·  í…ì…˜: {stats['avg_tension']:.2f}")
        print(f"   ìµœëŒ€ í…ì…˜: {stats['max_tension']:.2f}")
        print(f"   ìµœì†Œ í…ì…˜: {stats['min_tension']:.2f}")
        print(f"   í‘œì¤€í¸ì°¨: {stats['std_tension']:.2f}")
        
        print(f"\nâœ‚ï¸ í¸ì§‘ ì œì•ˆ:")
        print(f"   í•˜ì´ë¼ì´íŠ¸: {stats['highlight_count']}ê°œ")
        print(f"   ì»· í¬ì¸íŠ¸: {stats['cut_point_count']}ê°œ")
        print(f"   ì €ì—ë„ˆì§€ êµ¬ê°„: {stats['low_energy_count']}ê°œ")
        
        print(f"\nğŸµ ìŒì„± ì •ë³´:")
        print(f"   ìŒì„± í™œë™ ë¹„ìœ¨: {stats['voice_activity_ratio']:.1%}")
        
        # ìƒìœ„ 3ê°œ í•˜ì´ë¼ì´íŠ¸
        highlights = self.tension_data['edit_suggestions']['highlights']
        if highlights:
            top_highlights = sorted(highlights, key=lambda x: x['tension'], reverse=True)[:3]
            print(f"\nğŸ¯ ì£¼ìš” í•˜ì´ë¼ì´íŠ¸:")
            for i, hl in enumerate(top_highlights, 1):
                time_str = str(timedelta(seconds=int(hl['timestamp'])))
                print(f"   {i}. {time_str} (í…ì…˜: {hl['tension']:.2f})")
        
        print("="*60)


# ì£¼í”¼í„°ë©ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í¸ì˜ í•¨ìˆ˜ë“¤
def quick_load_and_visualize(filename_pattern: str, auto_detect_faces: bool = True) -> TensionVisualizer:
    """
    ë¹ ë¥¸ ë¡œë“œ ë° ì‹œê°í™” (ì£¼í”¼í„°ë© ìš©)
    
    Args:
        filename_pattern: íŒŒì¼ëª… íŒ¨í„´
        auto_detect_faces: ì–¼êµ´ í´ë” ìë™ ê°ì§€ ì—¬ë¶€
        
    Returns:
        TensionVisualizer: ì´ˆê¸°í™”ëœ ì‹œê°í™” ê°ì²´
    """
    viz = TensionVisualizer()
    if viz.load_tension_data(filename_pattern):
        # ì–¼êµ´ í´ë” ìë™ ê°ì§€
        if auto_detect_faces:
            viz.auto_find_faces_dir()
        viz.show_summary()
        return viz
    else:
        return None

def show_all_plots(filename_pattern: str, auto_detect_faces: bool = True) -> None:
    """
    ëª¨ë“  í”Œë¡¯ì„ í•œë²ˆì— í‘œì‹œ (ì£¼í”¼í„°ë© ìš©)
    
    Args:
        filename_pattern: íŒŒì¼ëª… íŒ¨í„´
    """
    viz = TensionVisualizer()
    if viz.load_tension_data(filename_pattern):
        viz.plot_tension_curves()
        viz.plot_emotion_pie_chart()
        viz.show_emotion_peak_faces()
    else:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ¨ TensionVisualizer í…ŒìŠ¤íŠ¸")
    
    # ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥
    print("\nğŸ“‹ ì£¼í”¼í„°ë© ì‚¬ìš© ì˜ˆì‹œ:")
    print("```python")
    print("from tension_visualizer import TensionVisualizer, quick_load_and_visualize")
    print("")
    print("# ë°©ë²• 1: ë‹¨ê³„ë³„ ì‹œê°í™” (ìë™ ì–¼êµ´ í´ë” ê°ì§€)")
    print("viz = TensionVisualizer()")
    print("viz.load_tension_data('your_filename_pattern')")
    print("viz.auto_find_faces_dir()         # HDF5ì—ì„œ ìë™ ê°ì§€")
    print("viz.plot_tension_curves()        # ì…€ 1")
    print("viz.plot_emotion_pie_chart()     # ì…€ 2")
    print("viz.show_emotion_peak_faces()    # ì…€ 3")
    print("")
    print("# ë°©ë²• 2: ë¹ ë¥¸ ë¡œë“œ (ìë™ ê°ì§€ í¬í•¨)")
    print("viz = quick_load_and_visualize('your_filename_pattern')")
    print("viz.plot_tension_curves()")
    print("")
    print("# ë°©ë²• 3: ëª¨ë“  í”Œë¡¯ í•œë²ˆì— (ìë™ ê°ì§€ í¬í•¨)")
    print("show_all_plots('your_filename_pattern')")
    print("")
    print("# ë°©ë²• 4: ìˆ˜ë™ í´ë” ì§€ì •")
    print("viz = TensionVisualizer(debug_faces_dir='custom_path/chimchakman')")
    print("viz.load_tension_data('your_filename_pattern')")
    print("")
    print("# ğŸ“ íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ëª… í˜•ì‹: timestamp_015750_face0_chimchakman_sim0.748.jpg")