#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import numpy as np
import h5py
from typing import Dict, List, Tuple, Optional
import logging
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
current_file = Path(__file__)
project_root = current_file.parent.parent.parent  # pipeline/modules/clip_refiner.py
sys.path.insert(0, str(project_root))

# íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹° import
sys.path.append('pipeline')
from utils.pipeline_utils import PipelineUtils


class ClipRefiner:
    """
    VAD(Voice Activity Detection) ê¸°ë°˜ìœ¼ë¡œ í´ë¦½ ê²½ê³„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì •í•˜ëŠ” ëª¨ë“ˆ
    
    ì„ íƒëœ í´ë¦½ì˜ ì‹œì‘/ë ë¶€ë¶„ì„ VAD ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì§€ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
    - ë°œí™”ê°€ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šë„ë¡ ì¡°ì •
    - ìµœëŒ€ 3ì´ˆê¹Œì§€ í´ë¦½ ê²½ê³„ í™•ì¥ ê°€ëŠ¥
    """
    
    def __init__(self, config: Dict, logger: Optional[logging.Logger] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config (Dict): ì„¤ì • ì •ë³´
            logger (logging.Logger, optional): ë¡œê±° ê°ì²´
        """
        self.config = config
        self.logger = logger or logging.getLogger(__name__)
        
        # VAD ê´€ë ¨ ì„¤ì • (êµ¬ì¡° í†µì¼)
        refiner_config = config.get('clip_refiner', {})
        
        # í‚¤ ì´ë¦„ í†µì¼ (ì´ì „ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€)
        self.max_extend_seconds = refiner_config.get('max_extend_seconds', 3.0)
        self.silence_padding = refiner_config.get('silence_padding', 0.05)
        self.extend_on_speech_boundary = refiner_config.get('extend_on_speech_boundary', True)
        
        self.logger.info(f"í´ë¦½ ê²½ê³„ ì¡°ì • ëª¨ë“ˆ ì´ˆê¸°í™”: ìµœëŒ€ í™•ì¥ {self.max_extend_seconds}ì´ˆ")
    
    def refine_clips(self, selected_clips: List[Dict], audio_data: Dict, video_name: str) -> List[Dict]:
        """
        ì„ íƒëœ í´ë¦½ë“¤ì˜ ê²½ê³„ ì¡°ì •
        
        Args:
            selected_clips (List[Dict]): ì„ íƒëœ í´ë¦½ ëª©ë¡
            audio_data (Dict): ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë°ì´í„° (VAD í¬í•¨)
            video_name (str): ë¹„ë””ì˜¤ ì´ë¦„
            
        Returns:
            List[Dict]: ê²½ê³„ê°€ ì¡°ì •ëœ í´ë¦½ ëª©ë¡
        """
        self.logger.info(f"í´ë¦½ ê²½ê³„ ì¡°ì • ì‹œì‘: {len(selected_clips)}ê°œ í´ë¦½")
        
        # VAD ë°ì´í„° ì¤€ë¹„
        vad_labels = audio_data['sequences']['vad_labels']
        timestamps = audio_data['sequences']['timestamps']
        
        refined_clips = []
        
        for clip in selected_clips:
            # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            clip_copy = self._convert_numpy_types(clip)
            
            start_time = clip_copy['start_time']
            end_time = clip_copy['end_time']
            
            # ì›ë³¸ ê²½ê³„ ì €ì¥
            clip_copy['original_start_time'] = start_time
            clip_copy['original_end_time'] = end_time
            
            # ê²½ê³„ ì¡°ì • (ë‹¨ìˆœí™”ëœ ë¡œì§)
            new_start, new_end = self._adjust_boundaries_simple(
                start_time, end_time, vad_labels, timestamps
            )
            
            # ì¡°ì •ëœ ê²½ê³„ ì ìš©
            clip_copy['start_time'] = float(new_start)
            clip_copy['end_time'] = float(new_end)
            clip_copy['duration'] = float(new_end - new_start)
            
            # ê²½ê³„ ì¡°ì • ì •ë³´ ì¶”ê°€
            clip_copy['boundary_refined'] = True
            clip_copy['start_extended'] = bool(new_start < start_time)
            clip_copy['end_extended'] = bool(new_end > end_time)
            
            refined_clips.append(clip_copy)
            
            self.logger.debug(
                f"í´ë¦½ ê²½ê³„ ì¡°ì •: {start_time:.2f}-{end_time:.2f} â†’ "
                f"{new_start:.2f}-{new_end:.2f} (í™•ì¥: {new_end-new_start-end_time+start_time:.2f}ì´ˆ)"
            )
        
        # ê²°ê³¼ ì €ì¥
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        safe_video_name = PipelineUtils.safe_filename(video_name)
        
        # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸ (configì— ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)
        base_dir = self.config.get('output', {}).get('base_dir', 'outputs/clip_analysis')
        
        output_dir = os.path.join(
            base_dir,
            safe_video_name
        )
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = PipelineUtils.get_timestamp()
        output_path = os.path.join(
            output_dir, 
            f"refined_clips_{safe_video_name}_{timestamp}.json"
        )
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                'video_name': video_name,
                'timestamp': timestamp,
                'clips': refined_clips,
                'refiner_config': {
                    'max_extend_seconds': self.max_extend_seconds,
                    'silence_padding': self.silence_padding,
                    'extend_on_speech_boundary': self.extend_on_speech_boundary
                }
            }, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"í´ë¦½ ê²½ê³„ ì¡°ì • ì™„ë£Œ: {len(refined_clips)}ê°œ í´ë¦½, ì €ì¥ ê²½ë¡œ: {output_path}")
        
        return refined_clips
    
    def _adjust_boundaries_simple(
        self, 
        start_time: float, 
        end_time: float, 
        vad_labels: np.ndarray, 
        timestamps: np.ndarray
    ) -> Tuple[float, float]:
        """
        ë‹¨ìˆœí™”ëœ VAD ê¸°ë°˜ í´ë¦½ ê²½ê³„ ì¡°ì •
        
        Args:
            start_time (float): ì›ë³¸ ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time (float): ì›ë³¸ ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
            vad_labels (np.ndarray): VAD ë ˆì´ë¸” ë°°ì—´ (1: ìŒì„±, 0: ë¹„ìŒì„±)
            timestamps (np.ndarray): íƒ€ì„ìŠ¤íƒ¬í”„ ë°°ì—´
            
        Returns:
            Tuple[float, float]: ì¡°ì •ëœ (ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„)
        """
        if not self.extend_on_speech_boundary:
            return start_time, end_time
        
        # ì‹œì‘ ì‹œê°„ ê¸°ì¤€ ì¸ë±ìŠ¤ ì°¾ê¸°
        start_idx = np.searchsorted(timestamps, start_time, side='right') - 1
        start_idx = max(0, start_idx)
        
        # ì¢…ë£Œ ì‹œê°„ ê¸°ì¤€ ì¸ë±ìŠ¤ ì°¾ê¸°
        end_idx = np.searchsorted(timestamps, end_time, side='left')
        end_idx = min(end_idx, len(timestamps) - 1)
        
        # ì‹œì‘ ê²½ê³„ ì¡°ì • (ë‹¨ìˆœí™”ëœ ë¡œì§)
        new_start = start_time
        if start_idx > 0:
            # í˜„ì¬ ì§€ì ì´ ìŒì„±ì´ë©´, ìŒì„± ì‹œì‘ ë¶€ë¶„ì„ ì°¾ì•„ í™•ì¥
            if vad_labels[start_idx] == 1:
                # ìµœëŒ€ 3ì´ˆ ì´ë‚´ì˜ ì•ìª½ ë¬´ìŒ ì§€ì  ì°¾ê¸°
                for i in range(start_idx, -1, -1):
                    if vad_labels[i] == 0:  # ë¬´ìŒ ì§€ì  ë°œê²¬
                        # ë¬´ìŒì—ì„œ silence_padding ì´ˆ ì•ìœ¼ë¡œ ì´ë™
                        new_start = max(timestamps[i] - self.silence_padding, 0)
                        break
                    # ìµœëŒ€ í™•ì¥ ë²”ìœ„ ë„ë‹¬
                    if start_time - timestamps[i] > self.max_extend_seconds:
                        new_start = start_time - self.max_extend_seconds
                        break
        
        # ì¢…ë£Œ ê²½ê³„ ì¡°ì • (ë‹¨ìˆœí™”ëœ ë¡œì§)
        new_end = end_time
        if end_idx < len(vad_labels) - 1:
            # í˜„ì¬ ì§€ì ì´ ìŒì„±ì´ë©´, ìŒì„± ì¢…ë£Œ ë¶€ë¶„ì„ ì°¾ì•„ í™•ì¥
            if vad_labels[end_idx] == 1:
                # ìµœëŒ€ 3ì´ˆ ì´ë‚´ì˜ ë’¤ìª½ ë¬´ìŒ ì§€ì  ì°¾ê¸°
                for i in range(end_idx, len(vad_labels)):
                    if vad_labels[i] == 0:  # ë¬´ìŒ ì§€ì  ë°œê²¬
                        # ë¬´ìŒì—ì„œ silence_padding ì´ˆ ë’¤ë¡œ ì´ë™
                        new_end = min(timestamps[i] + self.silence_padding, timestamps[-1])
                        break
                    # ìµœëŒ€ í™•ì¥ ë²”ìœ„ ë„ë‹¬
                    if timestamps[i] - end_time > self.max_extend_seconds:
                        new_end = end_time + self.max_extend_seconds
                        break
        
        # ìµœëŒ€ í™•ì¥ ë²”ìœ„ ì œí•œ
        new_start = max(new_start, start_time - self.max_extend_seconds)
        new_end = min(new_end, end_time + self.max_extend_seconds)
        
        return new_start, new_end

    def _convert_numpy_types(self, obj):
        """NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {k: self._convert_numpy_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return self._convert_numpy_types(obj.tolist())
        else:
            return obj


def main():
    """
    ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    """
    import argparse
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
    os.chdir(project_root)
    
    parser = argparse.ArgumentParser(description="VAD ê¸°ë°˜ í´ë¦½ ê²½ê³„ ì¡°ì • ëª¨ë“ˆ")
    parser.add_argument("clips_json", nargs='?', help="ì„ íƒëœ í´ë¦½ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("audio_h5", nargs='?', help="ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ HDF5 íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--clips", help="ì„ íƒëœ í´ë¦½ JSON íŒŒì¼ ê²½ë¡œ (named ì¸ì)")
    parser.add_argument("--audio", help="ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ HDF5 íŒŒì¼ ê²½ë¡œ (named ì¸ì)")
    parser.add_argument("--config", default="pipeline/configs/funclip_extraction_config.yaml", 
                        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    # í´ë¦½ ê²½ë¡œ ê²°ì • (positional ë˜ëŠ” named ì¸ì)
    clips_path = args.clips_json if args.clips_json else args.clips
    if not clips_path:
        print("âŒ ì˜¤ë¥˜: í´ë¦½ JSON íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤. positional ì¸ì ë˜ëŠ” --clips ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        parser.print_help()
        return
    
    # ì˜¤ë””ì˜¤ ê²½ë¡œ ê²°ì • (positional ë˜ëŠ” named ì¸ì)
    audio_path = args.audio_h5 if args.audio_h5 else args.audio
    if not audio_path:
        print("âŒ ì˜¤ë¥˜: ì˜¤ë””ì˜¤ HDF5 íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤. positional ì¸ì ë˜ëŠ” --audio ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        parser.print_help()
        return
    
    # ì„¤ì • ë¡œë“œ
    config = PipelineUtils.load_config(args.config)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • ì œê±° (ì˜¤ë¥˜ ë°œìƒ)
    # ëŒ€ì‹  ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
    if 'output' not in config:
        config['output'] = {'base_dir': 'outputs/clip_analysis'}
    elif 'base_dir' not in config['output']:
        config['output']['base_dir'] = 'outputs/clip_analysis'
    
    # ë¡œê¹… ì„¤ì • (logging í‚¤ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ë¡œê¹… ì„¤ì • ì‚¬ìš©)
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
    if not logger.handlers:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        logger.addHandler(console_handler)
    
    logger.info("ğŸ” í´ë¦½ ê²½ê³„ ì¡°ì • í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    
    # í´ë¦½ ë°ì´í„° ë¡œë“œ
    try:
        with open(clips_path, 'r', encoding='utf-8') as f:
            clips_data = json.load(f)
        
        # ë¹„ë””ì˜¤ ì´ë¦„ ì¶”ì¶œ
        video_name = clips_data.get('metadata', {}).get('video_name', None)
        if video_name is None:
            video_name = os.path.splitext(os.path.basename(clips_path))[0]
            if video_name.startswith('selected_clips_'):
                video_name = video_name[14:]  # 'selected_clips_' ì œê±°
        
        selected_clips = clips_data.get('clips', [])
        logger.info(f"ğŸ“Š í´ë¦½ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(selected_clips)}ê°œ í´ë¦½")
        logger.info(f"   ë¹„ë””ì˜¤: {video_name}")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
        audio_data = PipelineUtils.load_audio_hdf5(audio_path)
        if not audio_data:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {audio_path}")
            return
        
        # í´ë¦½ ê²½ê³„ ì¡°ì •
        refiner = ClipRefiner(config, logger)
        refined_clips = refiner.refine_clips(selected_clips, audio_data, video_name)
        
        print(f"\nâœ… í´ë¦½ ê²½ê³„ ì¡°ì • ì™„ë£Œ!")
        print(f"ğŸ“Š {len(refined_clips)}ê°œ í´ë¦½ ê²½ê³„ ì¡°ì •ë¨")
        
    except Exception as e:
        logger.error(f"âŒ í´ë¦½ ê²½ê³„ ì¡°ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 