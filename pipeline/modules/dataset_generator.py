#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import sys
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime
from scipy import stats

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
current_dir = os.path.dirname(os.path.abspath(__file__))
pipeline_root = os.path.dirname(current_dir)  # pipeline/
project_root = os.path.dirname(pipeline_root)  # project_root/
os.chdir(project_root)

# íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹° import
sys.path.append('pipeline')
from utils.pipeline_utils import PipelineUtils

class ChimchakmanDatasetGenerator:
    """
    ì¹¨ì°©ë§¨ ì¬ë¯¸ë„ ë°ì´í„°ì…‹ ìƒì„±ê¸°
    - HDF5 íŒŒì¼ë“¤ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
    - 3ê°€ì§€ ì‹¤í—˜ ì„¤ì • ì§€ì› (104/78/92ì°¨ì›)
    - ì—„ê²©í•œ ê²€ì¦ ì •ì±… ì ìš©
    - PipelineUtils í™œìš©ìœ¼ë¡œ ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©
    """
    
    def __init__(self, config_path: str = "pipeline/configs/dataset_config.yaml"):
        print(f"ğŸ—ï¸ ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™”")
        print(f"   ì„¤ì • íŒŒì¼: {config_path}")
        
        # PipelineUtilsë¡œ ì„¤ì • ë¡œë“œ
        self.config = PipelineUtils.load_config(config_path)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dirs = PipelineUtils.setup_output_directories(self.config)
        
        # ë¡œê¹… ì„¤ì •
        self.logger = PipelineUtils.setup_logging(self.config, self.output_dirs)
        
        # ê²½ë¡œ ì„¤ì •
        self.input_base_dir = self.config['dataset']['input_base_dir']
        
        # ë°ì´í„°ì…‹ ì¶œë ¥ ê²½ë¡œ
        self.dataset_output_dir = self.config['dataset']['dataset_output_dir']
        self.hdf5_filename = self.config['dataset']['hdf5_filename']
        self.dataset_path = os.path.join(self.dataset_output_dir, self.hdf5_filename)
        
        # ê²€ì¦ ì„¤ì •
        self.min_frames_per_segment = self.config['dataset']['validation']['min_frames_per_segment']
        self.min_duration = self.config['dataset']['validation']['min_clip_duration']
        self.max_duration = self.config['dataset']['validation']['max_clip_duration']
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.dataset_output_dir, exist_ok=True)
        
        self.logger.info("âœ… ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"   ì…ë ¥ ê²½ë¡œ: {self.input_base_dir}")
        self.logger.info(f"   ì¶œë ¥ ê²½ë¡œ: {self.dataset_path}")
        self.logger.info(f"   ê²€ì¦ ì •ì±…: êµ¬ê°„ë³„ ìµœì†Œ {self.min_frames_per_segment}í”„ë ˆì„")
    
    def is_clip_already_processed(self, clip_id: str) -> bool:
        """í´ë¦½ì´ ì´ë¯¸ ë°ì´í„°ì…‹ì— ìˆëŠ”ì§€ í™•ì¸"""
        if not os.path.exists(self.dataset_path):
            return False
        
        try:
            import h5py
            with h5py.File(self.dataset_path, 'r') as f:
                current_size = f.attrs.get('current_size', 0)
                if current_size == 0:
                    return False
                
                existing_clip_ids = f['clip_ids'][:current_size]
                # ë¬¸ìì—´ ë¹„êµ (bytes to str ë³€í™˜ í•„ìš”í•  ìˆ˜ ìˆìŒ)
                for existing_id in existing_clip_ids:
                    if isinstance(existing_id, bytes):
                        existing_id = existing_id.decode('utf-8')
                    if existing_id == clip_id:
                        return True
                return False
        except Exception as e:
            self.logger.warning(f"í´ë¦½ ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return False
        """í´ë¦½ í´ë” ìŠ¤ìº” ë° ìë™ ë¼ë²¨ë§"""
    def scan_clips(self) -> List[Dict]:
        """í´ë¦½ í´ë” ìŠ¤ìº” ë° ìë™ ë¼ë²¨ë§"""
        self.logger.info(f"ğŸ“ í´ë¦½ í´ë” ìŠ¤ìº”: {self.input_base_dir}")
        
        clips = []
        label_mapping = self.config['dataset']['label_mapping']
        extensions = self.config['dataset']['clip_extensions']
        
        for label_dir, label_value in label_mapping.items():
            folder_path = os.path.join(self.input_base_dir, label_dir)
            
            if not os.path.exists(folder_path):
                self.logger.warning(f"í´ë” ì—†ìŒ: {folder_path}")
                continue
            
            # í´ë¦½ íŒŒì¼ ì°¾ê¸°
            clip_files = []
            for ext in extensions:
                pattern = f"*{ext}"
                clip_files.extend(Path(folder_path).glob(pattern))
            
            for clip_path in clip_files:
                clip_id = clip_path.stem
                clips.append({
                    'clip_id': clip_id,
                    'clip_path': str(clip_path),
                    'label': label_value,
                    'label_name': label_dir
                })
            
            self.logger.info(f"   {label_dir}: {len(clip_files)}ê°œ í´ë¦½ (label={label_value})")
        
        self.logger.info(f"âœ… ì´ {len(clips)}ê°œ í´ë¦½ ë°œê²¬")
        return clips
    
    def find_pipeline_files(self, clip_id: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """í´ë¦½ IDë¡œ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ íŒŒì¼ë“¤ ì°¾ê¸°"""
        video_file = None
        audio_file = None
        tension_file = None
        
        base_dir = self.config['output']['base_dir']  # "dataset/preprocessed"
        preprocessed_dir = self.config['output']['preprocessed_dir']  # "preprocessed_data"
        
        # ë¹„ë””ì˜¤ HDF5 ì°¾ê¸°
        video_seq_dir = os.path.join(base_dir, preprocessed_dir, 
                                   self.config['output']['video_sequence_dir'])
        if os.path.exists(video_seq_dir):
            for file in os.listdir(video_seq_dir):
                if clip_id in file and file.endswith('.h5'):
                    video_file = os.path.join(video_seq_dir, file)
                    break
        
        # ì˜¤ë””ì˜¤ HDF5 ì°¾ê¸°  
        audio_seq_dir = os.path.join(base_dir, preprocessed_dir,
                                   self.config['output']['audio_sequence_dir'])
        if os.path.exists(audio_seq_dir):
            for file in os.listdir(audio_seq_dir):
                if clip_id in file and file.endswith('.h5'):
                    audio_file = os.path.join(audio_seq_dir, file)
                    break
        
        # í…ì…˜ JSON ì°¾ê¸°
        tension_dir = os.path.join(base_dir, self.config['output']['tension_analysis_dir'])
        if os.path.exists(tension_dir):
            for file in os.listdir(tension_dir):
                if clip_id in file and file.endswith('.json'):
                    tension_file = os.path.join(tension_dir, file)
                    break
        
        return video_file, audio_file, tension_file
    
    def load_tension_json(self, json_path: str) -> Optional[Dict]:
        """í…ì…˜ ë¶„ì„ JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                tension_data = json.load(f)
            
            return {
                'timestamps': np.array(tension_data['tension_timeline']['timestamps']),
                'combined_tension': np.array(tension_data['tension_timeline']['combined_tension'])
            }
        except Exception as e:
            self.logger.error(f"í…ì…˜ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def load_pipeline_data(self, video_h5_path: str, audio_h5_path: str, tension_json_path: str) -> Optional[Dict]:
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ íŒŒì¼ë“¤ì—ì„œ ë°ì´í„° ë¡œë“œ (PipelineUtils í™œìš©)"""
        try:
            # PipelineUtilsë¡œ HDF5 ë¡œë“œ
            video_data = PipelineUtils.load_video_hdf5(video_h5_path)
            audio_data = PipelineUtils.load_audio_hdf5(audio_h5_path)
            tension_data = self.load_tension_json(tension_json_path)
            
            if not video_data or not audio_data or not tension_data:
                return None
            
            # ë°ì´í„° ë™ê¸°í™” (ì˜¤ë””ì˜¤ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
            synced_data = self._synchronize_pipeline_data(video_data, audio_data, tension_data)
            return synced_data
            
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _synchronize_pipeline_data(self, video_data: Dict, audio_data: Dict, tension_data: Dict) -> Dict:
        """ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, í…ì…˜ ë°ì´í„° ë™ê¸°í™”"""
        audio_timestamps = audio_data['sequences']['timestamps']
        video_timestamps = video_data['sequences']['timestamps']
        tension_timestamps = tension_data['timestamps']
        
        # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì˜¤ë””ì˜¤ íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° ë³´ê°„
        synced_emotions = []
        synced_face_detected = []
        synced_tension = []
        
        for audio_ts in audio_timestamps:
            # ê°€ì¥ ê°€ê¹Œìš´ ë¹„ë””ì˜¤ í”„ë ˆì„ ì°¾ê¸°
            video_idx = np.argmin(np.abs(video_timestamps - audio_ts))
            
            emotion_frame = video_data['sequences']['emotions'][video_idx]
            if np.isnan(emotion_frame).any():
                emotion_frame = np.zeros(10)
            synced_emotions.append(emotion_frame)
            synced_face_detected.append(video_data['sequences']['face_detected'][video_idx])
            
            # ê°€ì¥ ê°€ê¹Œìš´ í…ì…˜ ê°’ ì°¾ê¸°
            tension_idx = np.argmin(np.abs(tension_timestamps - audio_ts))
            synced_tension.append(tension_data['combined_tension'][tension_idx])
        
        return {
            'timestamps': audio_timestamps,
            'emotions': np.array(synced_emotions),
            'face_detected': np.array(synced_face_detected),
            'rms_values': audio_data['sequences']['rms_values'],
            'vad_labels': audio_data['sequences']['vad_labels'],
            'tension_values': np.array(synced_tension),
            'analysis_interval': audio_data['metadata']['analysis_interval'],
            'duration': video_data['metadata']['duration']
        }
    
    def validate_clip(self, data: Dict, config_name: str) -> Tuple[bool, str]:
        """í´ë¦½ ê²€ì¦ (ì—„ê²©í•œ ì •ì±…)"""
        duration = data['duration']
        
        # ê¸¸ì´ ê²€ì¦
        if duration < self.min_duration or duration > self.max_duration:
            return False, f"ê¸¸ì´ ë¶€ì í•©: {duration:.1f}ì´ˆ ({self.min_duration}-{self.max_duration}ì´ˆ ë²”ìœ„ ë²—ì–´ë‚¨)"
        
        # êµ¬ê°„ë³„ ì–¼êµ´ í”„ë ˆì„ ìˆ˜ ê²€ì¦
        config = self.config['dataset']['feature_configs'][config_name]
        num_segments = config['segments']
        
        total_frames = len(data['face_detected'])
        frames_per_segment = total_frames // num_segments
        
        for i in range(num_segments):
            start_idx = i * frames_per_segment
            end_idx = (i + 1) * frames_per_segment if i < num_segments - 1 else total_frames
            
            segment_faces = data['face_detected'][start_idx:end_idx]
            valid_frames = np.sum(segment_faces)
            
            if valid_frames < self.min_frames_per_segment:
                return False, f"êµ¬ê°„ {i+1}: {valid_frames}í”„ë ˆì„ < {self.min_frames_per_segment}í”„ë ˆì„"
        
        return True, "í†µê³¼"
    
    def extract_features(self, data: Dict, config_name: str) -> np.ndarray:
        """íŠ¹ì§• ì¶”ì¶œ (ì„¤ì •ë³„) - RMS íšŒê·€ íŠ¹ì„± ì¶”ê°€"""
        config = self.config['dataset']['feature_configs'][config_name]
        num_segments = config['segments']
        use_regression = config['use_regression']
        
        total_frames = len(data['emotions'])
        frames_per_segment = total_frames // num_segments
        
        features = []
        
        for i in range(num_segments):
            start_idx = i * frames_per_segment
            end_idx = (i + 1) * frames_per_segment if i < num_segments - 1 else total_frames
            
            # êµ¬ê°„ ë°ì´í„° ì¶”ì¶œ
            segment_emotions = data['emotions'][start_idx:end_idx]
            segment_rms = data['rms_values'][start_idx:end_idx]
            segment_vad = data['vad_labels'][start_idx:end_idx]
            segment_face = data['face_detected'][start_idx:end_idx]
            
            # ì–¼êµ´ ìˆëŠ” í”„ë ˆì„ë§Œ ì‚¬ìš©
            valid_mask = segment_face > 0
            if np.sum(valid_mask) > 0:
                valid_emotions = segment_emotions[valid_mask]
                
                # ì–‘ìˆ˜ ë³€í™˜ í›„ ê°ì • íŠ¹ì§• ê³„ì‚°
                positive_emotions = np.maximum(valid_emotions, 0)
                
                # ê°ì • íŠ¹ì§• (20ì°¨ì›: í‰ê·  10 + í‘œì¤€í¸ì°¨ 10)
                emotion_mean = np.mean(positive_emotions, axis=0)
                emotion_std = np.std(positive_emotions, axis=0)
                
                # íšŒê·€ íŠ¹ì§• (20ì°¨ì› ì¶”ê°€)
                if use_regression:
                    emotion_slope = []
                    emotion_r2 = []
                    
                    for dim in range(10):
                        if len(positive_emotions) >= 3:  # ìµœì†Œ 3ê°œ ì  í•„ìš”
                            y = positive_emotions[:, dim]
                            x = np.arange(len(y))
                            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
                            emotion_slope.append(slope)
                            emotion_r2.append(max(0, r_value ** 2))  # ìŒìˆ˜ ë°©ì§€
                        else:
                            emotion_slope.append(0.0)
                            emotion_r2.append(0.0)
                    
                    emotion_features = np.concatenate([
                        emotion_mean,      # 10ì°¨ì›
                        emotion_std,       # 10ì°¨ì›  
                        emotion_slope,     # 10ì°¨ì›
                        emotion_r2         # 10ì°¨ì›
                    ])  # ì´ 40ì°¨ì›
                else:
                    emotion_features = np.concatenate([
                        emotion_mean,      # 10ì°¨ì›
                        emotion_std        # 10ì°¨ì›
                    ])  # ì´ 20ì°¨ì›
            else:
                # ì–¼êµ´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
                if use_regression:
                    emotion_features = np.zeros(40)
                else:
                    emotion_features = np.zeros(20)
            
            # ğŸ†• ì˜¤ë””ì˜¤ íŠ¹ì§• í™•ì¥ (RMS íšŒê·€ ì¶”ê°€)
            rms_mean = np.mean(segment_rms)
            rms_std = np.std(segment_rms)
            
            # RMS íšŒê·€ ë¶„ì„
            if len(segment_rms) >= 3 and np.std(segment_rms) > 1e-8:
                x = np.arange(len(segment_rms))
                slope, intercept, r_value, p_value, std_err = stats.linregress(x, segment_rms)
                rms_slope = slope
                rms_r2 = max(0, r_value ** 2)  # ìŒìˆ˜ ë°©ì§€
            else:
                rms_slope = 0.0
                rms_r2 = 0.0
            
            # ì˜¤ë””ì˜¤ íŠ¹ì§• (4ì°¨ì›: í‰ê·  + í‘œì¤€í¸ì°¨ + ê¸°ìš¸ê¸° + RÂ²)
            audio_features = np.array([
                rms_mean,
                rms_std,
                rms_slope,
                rms_r2
            ])
            
            # VAD íŠ¹ì§• (1ì°¨ì›: ë°œí™” ë¹„ìœ¨)
            vad_features = np.array([
                np.mean(segment_vad)
            ])
            
            # í…ì…˜ íŠ¹ì§• (3ì°¨ì›: í‰ê·  + í‘œì¤€í¸ì°¨ + ìµœëŒ€ê°’)
            segment_tension = data['tension_values'][start_idx:end_idx]
            
            tension_features = np.array([
                np.mean(segment_tension),
                np.std(segment_tension),
                np.max(segment_tension)
            ])
            
            # êµ¬ê°„ íŠ¹ì§• ê²°í•©
            if use_regression:
                segment_features = np.concatenate([
                    emotion_features,  # 40ì°¨ì›
                    audio_features,    # 4ì°¨ì› (ê¸°ì¡´ 2ì°¨ì› â†’ 4ì°¨ì›)
                    vad_features,      # 1ì°¨ì›
                    tension_features   # 3ì°¨ì›
                ])  # ì´ 48ì°¨ì› (ê¸°ì¡´ 46ì°¨ì› â†’ 48ì°¨ì›)
            else:
                segment_features = np.concatenate([
                    emotion_features,  # 20ì°¨ì›
                    audio_features,    # 4ì°¨ì› (ê¸°ì¡´ 2ì°¨ì› â†’ 4ì°¨ì›)
                    vad_features,      # 1ì°¨ì›
                    tension_features   # 3ì°¨ì›
                ])  # ì´ 28ì°¨ì› (ê¸°ì¡´ 26ì°¨ì› â†’ 28ì°¨ì›)
            
            features.extend(segment_features)
        
        return np.array(features)
    
    def create_or_append_dataset(self, features_dict: Dict, label: int, clip_id: str):
        """HDF5 ë°ì´í„°ì…‹ ìƒì„± ë˜ëŠ” ì¶”ê°€"""
        import h5py
        
        if not os.path.exists(self.dataset_path):
            # ìƒˆ ë°ì´í„°ì…‹ ìƒì„±
            self._create_new_dataset(features_dict, label, clip_id)
        else:
            # ê¸°ì¡´ ë°ì´í„°ì…‹ì— ì¶”ê°€
            self._append_to_dataset(features_dict, label, clip_id)
    
    def _create_new_dataset(self, features_dict: Dict, label: int, clip_id: str):
        """ìƒˆ HDF5 ë°ì´í„°ì…‹ ìƒì„±"""
        import h5py
        
        self.logger.info(f"ğŸ“¦ ìƒˆ ë°ì´í„°ì…‹ ìƒì„±: {self.dataset_path}")
        
        initial_size = self.config['dataset']['hdf5']['initial_size']
        
        with h5py.File(self.dataset_path, 'w') as f:
            # ë©”íƒ€ë°ì´í„°
            f.attrs['dataset_name'] = self.config['dataset']['dataset_name']
            f.attrs['created_at'] = datetime.now().isoformat()
            f.attrs['version'] = '1.0'
            
            # ê° ì„¤ì •ë³„ íŠ¹ì§• ë°ì´í„°ì…‹
            for config_name, features in features_dict.items():
                config = self.config['dataset']['feature_configs'][config_name]
                dims = config['dimensions']
                
                # íŠ¹ì§• ë°ì´í„°ì…‹
                f.create_dataset(f'features_{config_name}', 
                               shape=(initial_size, dims),
                               dtype='float32',
                               compression=None)
                f[f'features_{config_name}'][0] = features
            
            # ë¼ë²¨ ë°ì´í„°ì…‹
            f.create_dataset('labels', 
                           shape=(initial_size,),
                           dtype='int32',
                           compression=None)
            f['labels'][0] = label
            
            # í´ë¦½ ID ë°ì´í„°ì…‹
            dt = h5py.special_dtype(vlen=str)
            f.create_dataset('clip_ids',
                           shape=(initial_size,),
                           dtype=dt,
                           compression=None)
            f['clip_ids'][0] = clip_id
            
            # í˜„ì¬ í¬ê¸° ì¶”ì 
            f.attrs['current_size'] = 1
    
    def _append_to_dataset(self, features_dict: Dict, label: int, clip_id: str):
        """ê¸°ì¡´ ë°ì´í„°ì…‹ì— ì¶”ê°€"""
        import h5py
        
        with h5py.File(self.dataset_path, 'a') as f:
            current_size = f.attrs['current_size']
            
            # ê° ì„¤ì •ë³„ íŠ¹ì§• ì¶”ê°€
            for config_name, features in features_dict.items():
                dataset_name = f'features_{config_name}'
                
                # í•„ìš”ì‹œ í¬ê¸° í™•ì¥
                if current_size >= f[dataset_name].shape[0]:
                    new_size = f[dataset_name].shape[0] * 2
                    f[dataset_name].resize((new_size, f[dataset_name].shape[1]))
                
                f[dataset_name][current_size] = features
            
            # ë¼ë²¨ ì¶”ê°€
            if current_size >= f['labels'].shape[0]:
                f['labels'].resize((f['labels'].shape[0] * 2,))
            f['labels'][current_size] = label
            
            # í´ë¦½ ID ì¶”ê°€
            if current_size >= f['clip_ids'].shape[0]:
                f['clip_ids'].resize((f['clip_ids'].shape[0] * 2,))
            f['clip_ids'][current_size] = clip_id
            
            # í¬ê¸° ì—…ë°ì´íŠ¸
            f.attrs['current_size'] = current_size + 1
    
    def generate_dataset(self) -> Dict:
        """ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±"""
        PipelineUtils.print_step_banner(6, "ë°ì´í„°ì…‹ ìƒì„±", "íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ í†µí•© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜")
        
        # í´ë¦½ ìŠ¤ìº”
        clips = self.scan_clips()
        if not clips:
            raise ValueError("ì²˜ë¦¬í•  í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤")
        
        stats = {
            'total_clips': len(clips),
            'processed_clips': 0,
            'failed_clips': 0,
            'label_distribution': {},
            'config_results': {}
        }
        
        # ê° í´ë¦½ ì²˜ë¦¬
        for i, clip in enumerate(clips):
            self.logger.info(f"\nğŸ“¹ í´ë¦½ ì²˜ë¦¬ {i+1}/{len(clips)}: {clip['clip_id']}")
            
            # ì¤‘ë³µ ê²€ì‚¬
            if self.is_clip_already_processed(clip['clip_id']):
                self.logger.info(f"â© ì´ë¯¸ ì²˜ë¦¬ëœ í´ë¦½, ê±´ë„ˆë›°ê¸°: {clip['clip_id']}")
                stats['processed_clips'] += 1  # ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                label_name = clip['label_name']
                stats['label_distribution'][label_name] = stats['label_distribution'].get(label_name, 0) + 1
                continue
            
            try:
                # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ íŒŒì¼ë“¤ ì°¾ê¸°
                video_h5, audio_h5, tension_json = self.find_pipeline_files(clip['clip_id'])
                if not video_h5 or not audio_h5 or not tension_json:
                    missing = []
                    if not video_h5: missing.append("video_h5")
                    if not audio_h5: missing.append("audio_h5") 
                    if not tension_json: missing.append("tension_json")
                    self.logger.warning(f"íŒŒì¼ ì—†ìŒ: {missing}")
                    stats['failed_clips'] += 1
                    continue
                
                # ë°ì´í„° ë¡œë“œ
                data = self.load_pipeline_data(video_h5, audio_h5, tension_json)
                if data is None:
                    self.logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                    stats['failed_clips'] += 1
                    continue
                
                # ê° ì„¤ì •ë³„ íŠ¹ì§• ì¶”ì¶œ
                features_dict = {}
                valid_configs = []
                
                for config_name in self.config['dataset']['feature_configs'].keys():
                    # ê²€ì¦
                    is_valid, reason = self.validate_clip(data, config_name)
                    if not is_valid:
                        self.logger.warning(f"{config_name} ê²€ì¦ ì‹¤íŒ¨: {reason}")
                        continue
                    
                    # íŠ¹ì§• ì¶”ì¶œ
                    features = self.extract_features(data, config_name)
                    features_dict[config_name] = features
                    valid_configs.append(config_name)
                    self.logger.info(f"âœ… {config_name}: {len(features)}ì°¨ì› íŠ¹ì§• ì¶”ì¶œ")
                
                # ìœ íš¨í•œ ì„¤ì •ì´ ìˆìœ¼ë©´ ë°ì´í„°ì…‹ì— ì¶”ê°€
                if features_dict:
                    self.create_or_append_dataset(features_dict, clip['label'], clip['clip_id'])
                    stats['processed_clips'] += 1
                    
                    # ë¼ë²¨ ë¶„í¬ ì—…ë°ì´íŠ¸
                    label_name = clip['label_name']
                    stats['label_distribution'][label_name] = stats['label_distribution'].get(label_name, 0) + 1
                    
                    self.logger.info(f"âœ… ë°ì´í„°ì…‹ ì¶”ê°€ ì™„ë£Œ")
                else:
                    self.logger.error(f"ëª¨ë“  ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
                    stats['failed_clips'] += 1
                
            except Exception as e:
                self.logger.error(f"í´ë¦½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                stats['failed_clips'] += 1
        
        PipelineUtils.print_completion_banner(6, "ë°ì´í„°ì…‹ ìƒì„±", 
            f"ì²˜ë¦¬: {stats['processed_clips']}ê°œ, ì‹¤íŒ¨: {stats['failed_clips']}ê°œ, ë¶„í¬: {stats['label_distribution']}")
        
        return stats


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì¹¨ì°©ë§¨ ì¬ë¯¸ë„ ë°ì´í„°ì…‹ ìƒì„±')
    parser.add_argument('--config', default='pipeline/configs/dataset_config.yaml',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    try:
        generator = ChimchakmanDatasetGenerator(args.config)
        stats = generator.generate_dataset()
        
        print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ!")
        print(f"ğŸ“„ ì €ì¥ ìœ„ì¹˜: {generator.dataset_path}")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()