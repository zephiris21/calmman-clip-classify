#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import json
import yaml
import numpy as np
import joblib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
current_file = Path(__file__)
project_root = current_file.parent.parent.parent  # pipeline/modules/window_generator.py
sys.path.insert(0, str(project_root))

# íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹° ë° ê¸°ì¡´ ëª¨ë“ˆ import
sys.path.append('pipeline')
from utils.pipeline_utils import PipelineUtils


class WindowGenerator:
    """
    í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìœˆë„ìš° ìƒì„± ë° ì¬ë¯¸ë„ ì ìˆ˜ ê³„ì‚°
    - í´ëŸ¬ìŠ¤í„°ë³„ ë‹¤ì–‘í•œ ê¸¸ì´ ìœˆë„ìš° ìƒì„± (3/4 ì§€ì  ë°°ì¹˜)
    - dataset_generator íŠ¹ì§• ì¶”ì¶œ ë¡œì§ ì¬í™œìš©
    - XGBoost ëª¨ë¸ë¡œ ì¬ë¯¸ë„ ì ìˆ˜ ì˜ˆì¸¡
    """
    
    def __init__(self, config_path: str = None):
        """
        ìœˆë„ìš° ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            config_path (str): config íŒŒì¼ ê²½ë¡œ
        """
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
        os.chdir(project_root)
        
        self.logger = logging.getLogger(__name__)
        
        # Config ë¡œë“œ
        if config_path is None:
            config_path = "pipeline/configs/funclip_extraction_config.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ìœˆë„ìš° ìƒì„± íŒŒë¼ë¯¸í„°
        window_config = config['window_generation']
        self.window_lengths = self._get_window_lengths(window_config)
        self.step_size = window_config['step_size']  # 1ì´ˆ
        self.position_ratio = window_config['position_ratio']  # 0.75 (3/4 ì§€ì )
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
        self.feature_batch_size = 100   # íŠ¹ì§• ì¶”ì¶œ ë°°ì¹˜ í¬ê¸°
        self.prediction_batch_size = 500  # ì˜ˆì¸¡ ë°°ì¹˜ í¬ê¸°
        
        # XGBoost ëª¨ë¸ ë¡œë“œ
        model_path = config['model']['path']
        if not os.path.isabs(model_path):
            model_path = os.path.join(project_root, model_path)
        
        self.model = joblib.load(model_path)
        
        self.logger.info(f"âœ… ìœˆë„ìš° ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"   ìœˆë„ìš° ê¸¸ì´: {len(self.window_lengths)}ê°œ ({min(self.window_lengths)}~{max(self.window_lengths)}ì´ˆ)")
        self.logger.info(f"   ìœ„ì¹˜ ë¹„ìœ¨: {self.position_ratio} (3/4 ì§€ì  ë°°ì¹˜)")
        self.logger.info(f"   XGBoost ëª¨ë¸: {os.path.relpath(model_path)}")
        self.logger.info(f"   ë°°ì¹˜ í¬ê¸°: íŠ¹ì§•ì¶”ì¶œ {self.feature_batch_size}, ì˜ˆì¸¡ {self.prediction_batch_size}")
    
    def _get_window_lengths(self, window_config: Dict) -> List[int]:
        """ìœˆë„ìš° ê¸¸ì´ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        # ë°©ë²• 1: length_range ì‚¬ìš©
        if 'length_range' in window_config:
            range_config = window_config['length_range']
            return list(range(
                int(range_config['min']),
                int(range_config['max']) + 1,
                int(range_config.get('step', 1))
            ))
        
        # ë°©ë²• 2: ëª…ì‹œì  lengths ë¦¬ìŠ¤íŠ¸
        elif 'lengths' in window_config:
            # ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜
            lengths = window_config['lengths']
            return [int(length) for length in lengths]
        
        # ë°©ë²• 3: recommended + additional (ê¸°ë³¸ê°’)
        else:
            recommended = window_config.get('recommended_lengths', [20, 25, 30])
            additional = window_config.get('additional_lengths', [18, 22, 28, 35, 40])
            
            # ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            recommended = [int(x) for x in recommended]
            additional = [int(x) for x in additional]
            
            all_lengths = list(set(recommended + additional))
            all_lengths.sort()
            
            return all_lengths
    
    def load_clusters(self, clusters_json_path: str) -> Dict:
        """í´ëŸ¬ìŠ¤í„° JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(clusters_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            clusters = data['clusters']
            metadata = data['metadata']
            
            self.logger.info(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ë¡œë“œ ì™„ë£Œ: {len(clusters)}ê°œ")
            self.logger.info(f"   ì›ë³¸ í•˜ì´ë¼ì´íŠ¸: {metadata['total_highlights']}ê°œ")
            self.logger.info(f"   í™•ì¥ëœ í´ëŸ¬ìŠ¤í„°: {metadata['single_expanded_count']}ê°œ")
            if 'video_name' in metadata:
                self.logger.info(f"   ë¹„ë””ì˜¤: {metadata['video_name']}")
            
            return data
            
        except Exception as e:
            self.logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def generate_cluster_windows(self, cluster_data: Dict, video_duration: float) -> List[Dict]:
        """
        í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìœˆë„ìš° ìƒì„±
        
        Args:
            cluster_data (Dict): í´ëŸ¬ìŠ¤í„° ë°ì´í„° (ì „ì²´ ë°ì´í„°)
            video_duration (float): ì˜ìƒ ì „ì²´ ê¸¸ì´ (ì´ˆ)
            
        Returns:
            List[Dict]: ìƒì„±ëœ ìœˆë„ìš° ë¦¬ìŠ¤íŠ¸
        """
        self.logger.info("ğŸ” í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìœˆë„ìš° ìƒì„± ì‹œì‘...")
        
        windows = []
        window_id = 0
        
        # í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        clusters = cluster_data['clusters']
        
        for cluster in clusters:
            cluster_id = cluster['cluster_id']
            
            # í´ëŸ¬ìŠ¤í„° span ê³„ì‚° (ë˜ëŠ” ì´ë¯¸ ê³„ì‚°ëœ span ì‚¬ìš©)
            if 'span' in cluster:
                cluster_span = cluster['span']
                span_start = cluster_span['start']
                span_end = cluster_span['end']
            else:
                # spanì´ ì—†ëŠ” ê²½ìš° ì§ì ‘ ê³„ì‚°
                timestamps = [p['timestamp'] for p in cluster['points']]
                if not timestamps:
                    self.logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {cluster_id}: í¬ì¸íŠ¸ ì—†ìŒ")
                    continue
                span_start = min(timestamps)
                span_end = max(timestamps)
            
            self.logger.info(f"   í´ëŸ¬ìŠ¤í„° {cluster_id} ë²”ìœ„: {span_start:.1f}ì´ˆ ~ {span_end:.1f}ì´ˆ")
            
            # ê° ìœˆë„ìš° ê¸¸ì´ë³„ ìœˆë„ìš° ìƒì„±
            cluster_windows = 0
            for length in self.window_lengths:
                # ìœˆë„ìš° ì‹œì‘ ë²”ìœ„ ê³„ì‚° (í•˜ì´ë¼ì´íŠ¸ê°€ 3/4 ì§€ì ì— ì˜¤ë„ë¡)
                start_min = span_start - (length * self.position_ratio)
                start_max = span_end - (length * self.position_ratio)
                
                # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„± (1ì´ˆ ê°„ê²©)
                start = int(start_min) if start_min >= 0 else 0
                while start <= start_max and start <= video_duration - length:
                    end_time = start + length
                    
                    # ì˜ìƒ ë²”ìœ„ ì²´í¬
                    if end_time <= video_duration:
                        # ìœˆë„ìš°ì— í•´ë‹¹í•˜ëŠ” í•˜ì´ë¼ì´íŠ¸ ì‹œê°„ (í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ê°„ì  ì‚¬ìš©)
                        highlight_time = (span_start + span_end) / 2
                        
                        # í…ì…˜ ê°’ (í´ëŸ¬ìŠ¤í„° ë‚´ ìµœëŒ€ í…ì…˜ ë˜ëŠ” í‰ê·  í…ì…˜)
                        tensions = [float(p.get('tension', 0.0)) for p in cluster['points']]
                        highlight_tension = max(tensions) if tensions else 0.0
                        
                        windows.append({
                            'id': window_id,
                            'start_time': float(start),
                            'end_time': float(end_time),
                            'duration': length,
                            'cluster_id': cluster_id,
                            'highlight_time': float(highlight_time),
                            'highlight_tension': highlight_tension
                        })
                        window_id += 1
                        cluster_windows += 1
                    
                    # ë‹¤ìŒ ì‹œì‘ì  (1ì´ˆ ê°„ê²©)
                    start += self.step_size
            
            self.logger.debug(f"   í´ëŸ¬ìŠ¤í„° {cluster_id}: {cluster_windows}ê°œ ìœˆë„ìš°")
        
        self.logger.info(f"âœ… ìœˆë„ìš° ìƒì„± ì™„ë£Œ: {len(windows)}ê°œ")
        if clusters:
            self.logger.info(f"   í‰ê·  ìœˆë„ìš°/í´ëŸ¬ìŠ¤í„°: {len(windows)/len(clusters):.1f}ê°œ")
        
        return windows
    
    def load_pipeline_data(self, video_h5_path: str, audio_h5_path: str, tension_json_path: str) -> Dict:
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ë°ì´í„° ë¡œë“œ ë° ë™ê¸°í™”"""
        self.logger.info("ğŸ“‚ íŒŒì´í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # HDF5 íŒŒì¼ë“¤ ë¡œë“œ
            video_data = PipelineUtils.load_video_hdf5(video_h5_path)
            audio_data = PipelineUtils.load_audio_hdf5(audio_h5_path)
            
            # í…ì…˜ JSON ë¡œë“œ
            with open(tension_json_path, 'r', encoding='utf-8') as f:
                tension_data = json.load(f)
            
            # ë°ì´í„° ë™ê¸°í™” (ì˜¤ë””ì˜¤ 0.05ì´ˆ ê¸°ì¤€)
            synced_data = self._synchronize_pipeline_data(video_data, audio_data, tension_data)
            
            self.logger.info(f"âœ… ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ: {len(synced_data['timestamps'])}ê°œ í”„ë ˆì„")
            self.logger.info(f"   ì˜ìƒ ê¸¸ì´: {synced_data['duration']:.1f}ì´ˆ")
            
            return synced_data
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _synchronize_pipeline_data(self, video_data: Dict, audio_data: Dict, tension_data: Dict) -> Dict:
        """ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, í…ì…˜ ë°ì´í„° ë™ê¸°í™” (dataset_generator ë¡œì§ ì¬ì‚¬ìš©)"""
        audio_timestamps = audio_data['sequences']['timestamps']
        video_timestamps = video_data['sequences']['timestamps']
        tension_timestamps = np.array(tension_data['tension_timeline']['timestamps'])
        
        # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì˜¤ë””ì˜¤ íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° ë³´ê°„
        synced_emotions = []
        synced_face_detected = []
        synced_tension = []
        
        for audio_ts in audio_timestamps:
            # ê°€ì¥ ê°€ê¹Œìš´ ë¹„ë””ì˜¤ í”„ë ˆì„ ì°¾ê¸°
            video_idx = np.argmin(np.abs(video_timestamps - audio_ts))
            
            emotion_frame = video_data['sequences']['emotions'][video_idx]
            if np.isnan(emotion_frame).any():
                emotion_frame = np.zeros(10)
            synced_emotions.append(emotion_frame)
            synced_face_detected.append(video_data['sequences']['face_detected'][video_idx])
            
            # ê°€ì¥ ê°€ê¹Œìš´ í…ì…˜ ê°’ ì°¾ê¸°
            tension_idx = np.argmin(np.abs(tension_timestamps - audio_ts))
            synced_tension.append(tension_data['tension_timeline']['combined_tension'][tension_idx])
        
        return {
            'timestamps': audio_timestamps,
            'emotions': np.array(synced_emotions),
            'face_detected': np.array(synced_face_detected),
            'rms_values': audio_data['sequences']['rms_values'],
            'vad_labels': audio_data['sequences']['vad_labels'],
            'tension_values': np.array(synced_tension),
            'duration': video_data['metadata']['duration']
        }
    
    def extract_features_for_windows(self, windows: List[Dict], synced_data: Dict) -> np.ndarray:
        """
        ìœˆë„ìš°ë“¤ì— ëŒ€í•œ íŠ¹ì§• ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            windows (List[Dict]): ìœˆë„ìš° ë¦¬ìŠ¤íŠ¸
            synced_data (Dict): ë™ê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ë°ì´í„°
            
        Returns:
            np.ndarray: [num_windows, 112] íŠ¹ì§• ë°°ì—´
        """
        self.logger.info(f"ğŸ§© ìœˆë„ìš° íŠ¹ì§• ì¶”ì¶œ ì‹œì‘: {len(windows)}ê°œ")
        
        all_features = []
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(windows), self.feature_batch_size):
            batch_end = min(i + self.feature_batch_size, len(windows))
            batch_windows = windows[i:batch_end]
            
            # ë°°ì¹˜ íŠ¹ì§• ì¶”ì¶œ
            batch_features = []
            for window in batch_windows:
                try:
                    features = self._extract_window_features(window, synced_data)
                    batch_features.append(features)
                except Exception as e:
                    # ì‹¤íŒ¨í•œ ìœˆë„ìš°ëŠ” 0ë²¡í„°ë¡œ ì²˜ë¦¬
                    self.logger.warning(f"âš ï¸ ìœˆë„ìš° {window['id']} íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    batch_features.append(np.zeros(112))
            
            all_features.extend(batch_features)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            progress = batch_end / len(windows) * 100
            self.logger.info(f"   íŠ¹ì§• ì¶”ì¶œ ì§„í–‰: {batch_end}/{len(windows)} ({progress:.1f}%)")
        
        features_array = np.array(all_features)
        self.logger.info(f"âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {features_array.shape}")
        
        return features_array
    
    def _extract_window_features(self, window: Dict, synced_data: Dict) -> np.ndarray:
        """ë‹¨ì¼ ìœˆë„ìš° íŠ¹ì§• ì¶”ì¶œ (dataset_generator ë¡œì§ ì¬ì‚¬ìš©)"""
        # ìœˆë„ìš° ì‹œê°„ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°
        start_time = window['start_time']
        end_time = window['end_time']
        
        timestamps = synced_data['timestamps']
        start_idx = np.searchsorted(timestamps, start_time)
        end_idx = np.searchsorted(timestamps, end_time)
        
        # ìœˆë„ìš° ë°ì´í„° ì¶”ì¶œ
        window_data = {
            'emotions': synced_data['emotions'][start_idx:end_idx],
            'face_detected': synced_data['face_detected'][start_idx:end_idx],
            'rms_values': synced_data['rms_values'][start_idx:end_idx],
            'vad_labels': synced_data['vad_labels'][start_idx:end_idx],
            'tension_values': synced_data['tension_values'][start_idx:end_idx],
            'duration': end_time - start_time
        }
        
        # dataset_generatorì˜ extract_features ë¡œì§ ì¬ì‚¬ìš© (config1 = 4êµ¬ê°„)
        features = self._extract_features_config1(window_data)
        
        return features
    
    def _extract_features_config1(self, data: Dict) -> np.ndarray:
        """4êµ¬ê°„ íŠ¹ì§• ì¶”ì¶œ (dataset_generator ë¡œì§ ì¬ì‚¬ìš©)"""
        num_segments = 4  # config1
        
        total_frames = len(data['emotions'])
        if total_frames == 0:
            return np.zeros(112)  # 28ì°¨ì› Ã— 4êµ¬ê°„
        
        frames_per_segment = total_frames // num_segments
        
        features = []
        
        for i in range(num_segments):
            start_idx = i * frames_per_segment
            end_idx = (i + 1) * frames_per_segment if i < num_segments - 1 else total_frames
            
            # êµ¬ê°„ ë°ì´í„° ì¶”ì¶œ
            segment_emotions = data['emotions'][start_idx:end_idx]
            segment_rms = data['rms_values'][start_idx:end_idx]
            segment_vad = data['vad_labels'][start_idx:end_idx]
            segment_face = data['face_detected'][start_idx:end_idx]
            segment_tension = data['tension_values'][start_idx:end_idx]
            
            # ê°ì • íŠ¹ì§• (20ì°¨ì›)
            valid_mask = segment_face > 0
            if np.sum(valid_mask) > 0:
                valid_emotions = segment_emotions[valid_mask]
                positive_emotions = np.maximum(valid_emotions, 0)
                emotion_mean = np.mean(positive_emotions, axis=0)
                emotion_std = np.std(positive_emotions, axis=0)
                emotion_features = np.concatenate([emotion_mean, emotion_std])
            else:
                emotion_features = np.zeros(20)
            
            # VAD í•„í„°ë§ëœ ì˜¤ë””ì˜¤ íŠ¹ì§• (4ì°¨ì›)
            voice_mask = segment_vad > 0
            non_voice_mask = segment_vad == 0
            
            if np.sum(voice_mask) > 0:
                voice_rms_values = segment_rms[voice_mask]
                voice_rms_mean = np.mean(voice_rms_values)
                voice_rms_max = np.max(voice_rms_values)
            else:
                voice_rms_mean = 0.0
                voice_rms_max = 0.0
            
            if np.sum(non_voice_mask) > 0:
                background_rms_mean = np.mean(segment_rms[non_voice_mask])
            else:
                background_rms_mean = 0.0
            
            total_rms_std = np.std(segment_rms) if len(segment_rms) > 0 else 0.0
            
            audio_features = np.array([
                voice_rms_mean,
                voice_rms_max,
                background_rms_mean,
                total_rms_std
            ])
            
            # VAD íŠ¹ì§• (1ì°¨ì›)
            vad_features = np.array([
                np.mean(segment_vad) if len(segment_vad) > 0 else 0.0
            ])
            
            # í…ì…˜ íŠ¹ì§• (3ì°¨ì›)
            if len(segment_tension) > 0:
                tension_features = np.array([
                    np.mean(segment_tension),
                    np.std(segment_tension),
                    np.max(segment_tension)
                ])
            else:
                tension_features = np.zeros(3)
            
            # êµ¬ê°„ íŠ¹ì§• ê²°í•© (28ì°¨ì›)
            segment_features = np.concatenate([
                emotion_features,  # 20ì°¨ì›
                audio_features,    # 4ì°¨ì›
                vad_features,      # 1ì°¨ì›
                tension_features   # 3ì°¨ì›
            ])
            
            features.extend(segment_features)
        
        return np.array(features)  # 112ì°¨ì› (28 Ã— 4)
    
    def evaluate_with_xgb(self, features: np.ndarray) -> List[float]:
        """
        XGBoost ëª¨ë¸ë¡œ ì¬ë¯¸ë„ ì ìˆ˜ ì˜ˆì¸¡ (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            features (np.ndarray): [num_windows, 112] íŠ¹ì§• ë°°ì—´
            
        Returns:
            List[float]: ì¬ë¯¸ë„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ (0~1)
        """
        self.logger.info(f"ğŸ¤– XGBoost ì¬ë¯¸ë„ ì˜ˆì¸¡ ì‹œì‘: {len(features)}ê°œ")
        
        all_scores = []
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(features), self.prediction_batch_size):
            batch_end = min(i + self.prediction_batch_size, len(features))
            batch_features = features[i:batch_end]
            
            # ì˜ˆì¸¡ (Funny í´ë˜ìŠ¤ í™•ë¥ )
            probabilities = self.model.predict_proba(batch_features)
            fun_scores = probabilities[:, 1]  # í´ë˜ìŠ¤ 1 (Funny) í™•ë¥ 
            
            all_scores.extend(fun_scores.tolist())
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            progress = batch_end / len(features) * 100
            self.logger.info(f"   ì˜ˆì¸¡ ì§„í–‰: {batch_end}/{len(features)} ({progress:.1f}%)")
        
        self.logger.info(f"âœ… ì¬ë¯¸ë„ ì˜ˆì¸¡ ì™„ë£Œ")
        
        # ì ìˆ˜ í†µê³„
        scores_array = np.array(all_scores)
        self.logger.info(f"   ì ìˆ˜ ë²”ìœ„: {np.min(scores_array):.3f} ~ {np.max(scores_array):.3f}")
        self.logger.info(f"   í‰ê·  ì ìˆ˜: {np.mean(scores_array):.3f}")
        
        return all_scores
    
    def generate_and_score_windows(self, clusters_json_path: str, video_h5_path: str, 
                                  audio_h5_path: str, tension_json_path: str) -> Dict:
        """
        ì „ì²´ ìœˆë„ìš° ìƒì„± ë° ì ìˆ˜ ê³„ì‚° í”„ë¡œì„¸ìŠ¤
        
        Args:
            clusters_json_path (str): í´ëŸ¬ìŠ¤í„° JSON íŒŒì¼ ê²½ë¡œ
            video_h5_path (str): ë¹„ë””ì˜¤ HDF5 íŒŒì¼ ê²½ë¡œ
            audio_h5_path (str): ì˜¤ë””ì˜¤ HDF5 íŒŒì¼ ê²½ë¡œ
            tension_json_path (str): í…ì…˜ JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: scored_windows.json ë°ì´í„°
        """
        self.logger.info("ğŸ” ìœˆë„ìš° ìƒì„± ë° ì ìˆ˜ ê³„ì‚° í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        
        # 1. í´ëŸ¬ìŠ¤í„° ë¡œë“œ
        cluster_data = self.load_clusters(clusters_json_path)
        
        # 2. íŒŒì´í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ
        synced_data = self.load_pipeline_data(video_h5_path, audio_h5_path, tension_json_path)
        
        # 3. ìœˆë„ìš° ìƒì„±
        windows = self.generate_cluster_windows(cluster_data, synced_data['duration'])
        
        if not windows:
            raise ValueError("ìƒì„±ëœ ìœˆë„ìš°ê°€ ì—†ìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ë‚˜ ì˜ìƒ ê¸¸ì´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # 4. íŠ¹ì§• ì¶”ì¶œ
        features = self.extract_features_for_windows(windows, synced_data)
        
        # 5. XGBoost ì˜ˆì¸¡
        fun_scores = self.evaluate_with_xgb(features)
        
        # 6. ê²°ê³¼ ì¡°í•©
        for i, window in enumerate(windows):
            window['fun_score'] = fun_scores[i]
        
        # ë¹„ë””ì˜¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (í´ëŸ¬ìŠ¤í„° ë©”íƒ€ë°ì´í„°ì—ì„œ)
        video_name = cluster_data.get('metadata', {}).get('video_name', 'unknown')
        
        # 7. ê²°ê³¼ êµ¬ì„±
        result = {
            'metadata': {
                'video_name': video_name,
                'total_windows': len(windows),
                'video_duration': synced_data['duration'],
                'score_statistics': {
                    'mean': float(np.mean(fun_scores)),
                    'std': float(np.std(fun_scores)),
                    'min': float(np.min(fun_scores)),
                    'max': float(np.max(fun_scores))
                },
                'source_files': {
                    'clusters': os.path.basename(clusters_json_path),
                    'video_h5': os.path.basename(video_h5_path),
                    'audio_h5': os.path.basename(audio_h5_path),
                    'tension': os.path.basename(tension_json_path)
                },
                'generated_at': datetime.now().isoformat()
            },
            'generation_config': {
                'window_lengths': self.window_lengths,
                'position_ratio': self.position_ratio,
                'step_size': self.step_size,
                'model_path': os.path.relpath(self.model.get_booster().save_config())
                if hasattr(self.model, 'get_booster') else 'xgb_model'
            },
            'windows': windows
        }
        
        self.logger.info("ğŸ” ìœˆë„ìš° ìƒì„± ë° ì ìˆ˜ ê³„ì‚° ì™„ë£Œ!")
        self.logger.info(f"   ë¹„ë””ì˜¤: {video_name}")
        self.logger.info(f"   ìµœì¢… ìœˆë„ìš°: {len(windows)}ê°œ")
        self.logger.info(f"   í‰ê·  ì¬ë¯¸ë„: {np.mean(fun_scores):.3f}")
        
        return result
    
    def save_scored_windows(self, scored_windows: Dict, output_path: str) -> None:
        """
        ì ìˆ˜ê°€ ë§¤ê²¨ì§„ ìœˆë„ìš°ë“¤ì„ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            scored_windows (Dict): ì ìˆ˜ ë§¤ê²¨ì§„ ìœˆë„ìš° ë°ì´í„°
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
            if not os.path.isabs(output_path):
                output_path = os.path.join(project_root, output_path)
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # JSON ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(scored_windows, f, indent=2, ensure_ascii=False)
            
            # ìƒëŒ€ ê²½ë¡œë¡œ ë¡œê·¸ ì¶œë ¥
            relative_path = os.path.relpath(output_path, project_root)
            self.logger.info(f"ğŸ’¾ ì ìˆ˜ ìœˆë„ìš° ì €ì¥ ì™„ë£Œ: {relative_path}")
            
            # ìš”ì•½ ì •ë³´ ì¶œë ¥
            metadata = scored_windows['metadata']
            self.logger.info(f"   ì´ ìœˆë„ìš°: {metadata['total_windows']}ê°œ")
            self.logger.info(f"   í‰ê·  ì ìˆ˜: {metadata['score_statistics']['mean']:.3f}")
            if 'video_name' in metadata:
                self.logger.info(f"   ë¹„ë””ì˜¤: {metadata['video_name']}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì ìˆ˜ ìœˆë„ìš° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import argparse
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
    os.chdir(project_root)
    
    parser = argparse.ArgumentParser(description='ìœˆë„ìš° ìƒì„± ë° ì¬ë¯¸ë„ ì ìˆ˜ ê³„ì‚°')
    parser.add_argument('clusters_json', help='í´ëŸ¬ìŠ¤í„° JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('video_h5', help='ë¹„ë””ì˜¤ HDF5 íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('audio_h5', help='ì˜¤ë””ì˜¤ HDF5 íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('tension_json', help='í…ì…˜ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', help='ì¶œë ¥ JSON ê²½ë¡œ')
    parser.add_argument('--config', help='Config íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # ìœˆë„ìš° ìƒì„±ê¸° ì‹¤í–‰
        generator = WindowGenerator(config_path=args.config)
        
        # ìœˆë„ìš° ìƒì„± ë° ì ìˆ˜ ê³„ì‚°
        result = generator.generate_and_score_windows(
            args.clusters_json,
            args.video_h5,
            args.audio_h5,
            args.tension_json
        )
        
        # ê²°ê³¼ ì €ì¥
        if args.output:
            output_path = args.output
        else:
            # ê¸°ë³¸ ì¶œë ¥ ê²½ë¡œ ìƒì„±
            # í´ëŸ¬ìŠ¤í„° ê²½ë¡œì—ì„œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìœ ì§€í•˜ì—¬ ì €ì¥
            clusters_dir = os.path.dirname(args.clusters_json)
            
            # ë¹„ë””ì˜¤ ì´ë¦„ê³¼ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            video_name = result['metadata']['video_name']
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = os.path.join(clusters_dir, f'scored_windows_{video_name}_{timestamp}.json')
        
        generator.save_scored_windows(result, output_path)
        
        print(f"\nâœ… ìœˆë„ìš° ìƒì„± ë° ì ìˆ˜ ê³„ì‚° ì™„ë£Œ!")
        print(f"ğŸ“Š {result['metadata']['total_windows']}ê°œ ìœˆë„ìš° ìƒì„±")
        print(f"ğŸ¯ í‰ê·  ì¬ë¯¸ë„: {result['metadata']['score_statistics']['mean']:.3f}")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {os.path.relpath(output_path if os.path.isabs(output_path) else os.path.join(project_root, output_path), project_root)}")
        
    except Exception as e:
        print(f"âŒ ìœˆë„ìš° ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()