#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import yaml
import h5py
import numpy as np
import librosa
import webrtcvad
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime

class LongVideoAudioPreprocessor:
    """
    ê¸´ ì˜ìƒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ê¸° (VAD í†µí•© ë²„ì „)
    0.05ì´ˆ ë‹¨ìœ„ë¡œ RMS + VAD ì¶”ì¶œí•˜ì—¬ ì›ì‹œ ì‹œí€€ìŠ¤ ì €ìž¥
    ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ìš© ë°ì´í„° ì¤€ë¹„
    """
    
    def __init__(self, config_path: str = "video_analyzer/configs/inference_config.yaml"):
        """
        ê¸´ ì˜ìƒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = self._load_config(config_path)
        self._setup_logging()
        self._create_output_dirs()
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.sample_rate = self.config['audio']['sample_rate']
        self.analysis_interval = self.config['audio']['analysis_interval']  # 0.05ì´ˆ
        
        # VAD ì´ˆê¸°í™”
        self._init_vad()
        
        self.logger.info("âœ… ê¸´ ì˜ìƒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ (VAD í†µí•©)")
        self.logger.info(f"   ìƒ˜í”Œë ˆì´íŠ¸: {self.sample_rate}Hz")
        self.logger.info(f"   ë¶„ì„ ê°„ê²©: {self.analysis_interval}ì´ˆ")
        self.logger.info(f"   VAD ë¯¼ê°ë„: {self.vad_sensitivity}")
    
    def _init_vad(self):
        """WebRTC VAD ì´ˆê¸°í™”"""
        try:
            self.vad_sensitivity = self.config['audio']['vad_sensitivity']
            self.vad_frame_duration = self.config['audio']['vad_frame_duration']  # 10ms
            self.vad_aggregation_frames = self.config['audio']['vad_aggregation_frames']  # 5ê°œ
            self.vad_majority_threshold = self.config['audio']['vad_majority_threshold']  # 3ê°œ
            
            # WebRTC VAD ê°ì²´ ìƒì„±
            self.vad = webrtcvad.Vad(self.vad_sensitivity)
            
            # VAD í”„ë ˆìž„ í¬ê¸° ê³„ì‚° (16kHz ê¸°ì¤€)
            self.vad_frame_size = int(self.sample_rate * self.vad_frame_duration / 1000)  # 160 samples
            
            self.logger.info(f"âœ… WebRTC VAD ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info(f"   í”„ë ˆìž„ ê¸¸ì´: {self.vad_frame_duration}ms ({self.vad_frame_size} samples)")
            self.logger.info(f"   ì§‘ê³„ í”„ë ˆìž„: {self.vad_aggregation_frames}ê°œ â†’ {self.analysis_interval}ì´ˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ VAD ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _load_config(self, config_path: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        default_config = {
            'audio': {
                'sample_rate': 16000,
                'analysis_interval': 0.05,
                'vad_sensitivity': 2,
                'vad_frame_duration': 10,
                'vad_aggregation_frames': 5,
                'vad_majority_threshold': 3
            },
            'output': {
                'base_dir': 'video_analyzer',
                'preprocessed_dir': 'preprocessed_data',
                'audio_sequence_dir': 'audio_sequences'
            },
            'logging': {
                'level': 'INFO',
                'save_audio_statistics': True
            },
            'debug': {
                'save_vad_debug_info': False
            }
        }
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            # ê¸°ë³¸ê°’ê³¼ ë³‘í•©
            for key, value in default_config.items():
                if key not in config:
                    config[key] = value
                elif isinstance(value, dict):
                    for subkey, subvalue in value.items():
                        if subkey not in config[key]:
                            config[key][subkey] = subvalue
        else:
            config = default_config
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {config_path}")
        
        return config
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        self.logger = logging.getLogger('LongVideoAudioPreprocessor')
        self.logger.setLevel(getattr(logging, self.config['logging']['level']))
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
    
    def _create_output_dirs(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        base_dir = self.config['output']['base_dir']
        self.preprocessed_dir = os.path.join(base_dir, self.config['output']['preprocessed_dir'])
        self.audio_sequence_dir = os.path.join(self.preprocessed_dir, self.config['output']['audio_sequence_dir'])
        
        os.makedirs(self.audio_sequence_dir, exist_ok=True)
    
    def preprocess_long_video_audio(self, video_path: str) -> Optional[Dict]:
        """
        ê¸´ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (VAD í†µí•©)
        
        Args:
            video_path (str): ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ì •ë³´
        """
        if not os.path.exists(video_path):
            self.logger.error(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return None
        
        try:
            video_name = Path(video_path).stem
            self.logger.info(f"ðŸŽ¬ ê¸´ ì˜ìƒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹œìž‘: {video_name}")
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ (16kHzë¡œ ì§ì ‘ ë¡œë“œ)
            y, sr = librosa.load(video_path, sr=self.sample_rate)
            duration = len(y) / sr
            
            self.logger.info(f"   ì˜ìƒ ê¸¸ì´: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)")
            self.logger.info(f"   ë¡œë“œëœ ìƒ˜í”Œë ˆì´íŠ¸: {sr}Hz")
            
            # 0.05ì´ˆ ê°„ê²©ìœ¼ë¡œ RMS ì‹œí€€ìŠ¤ ì¶”ì¶œ
            rms_sequence = self._extract_rms_sequence(y, sr)
            
            # VAD ì‹œí€€ìŠ¤ ì¶”ì¶œ (NEW)
            vad_sequence = self._extract_vad_sequence(y, sr)
            
            # ì‹œí€€ìŠ¤ ê¸¸ì´ ë§žì¶”ê¸° (RMSì™€ VAD ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìžˆìŒ)
            min_length = min(len(rms_sequence), len(vad_sequence))
            rms_sequence = rms_sequence[:min_length]
            vad_sequence = vad_sequence[:min_length]
            
            # íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„±
            timestamps = np.arange(min_length) * self.analysis_interval
            
            # VAD í†µê³„ ê³„ì‚°
            vad_stats = self._calculate_vad_statistics(vad_sequence)
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'video_name': video_name,
                'video_path': video_path,
                'duration': duration,
                'sample_rate': sr,
                'analysis_interval': self.analysis_interval,
                'sequences': {
                    'rms_values': rms_sequence,
                    'vad_labels': vad_sequence,  # change_rates ëŒ€ì‹  VAD
                    'timestamps': timestamps
                },
                'metadata': {
                    'total_frames': min_length,
                    'frames_per_second': 1.0 / self.analysis_interval,  # 20 FPS
                    'processed_at': datetime.now().isoformat(),
                    'vad_statistics': vad_stats
                }
            }
            
            # HDF5ë¡œ ì €ìž¥
            hdf5_path = self._save_to_hdf5(result)
            result['hdf5_path'] = hdf5_path
            
            self.logger.info(f"   RMS ì‹œí€€ìŠ¤: {len(rms_sequence)}ê°œ í”„ë ˆìž„")
            self.logger.info(f"   VAD ì‹œí€€ìŠ¤: {len(vad_sequence)}ê°œ í”„ë ˆìž„")
            self.logger.info(f"   ë°œí™” ë¹„ìœ¨: {vad_stats['voice_activity_ratio']:.1%}")
            self.logger.info(f"   ì €ìž¥ ìœ„ì¹˜: {hdf5_path}")
            
            # ì˜¤ë””ì˜¤ í†µê³„ íŒŒì¼ ì €ìž¥
            if self.config['logging']['save_audio_statistics']:
                self._save_audio_statistics(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {video_path} - {e}")
            return None
    
    def _extract_rms_sequence(self, y: np.ndarray, sr: int) -> np.ndarray:
        """
        0.05ì´ˆ ê°„ê²©ìœ¼ë¡œ RMS ê°’ ì‹œí€€ìŠ¤ ì¶”ì¶œ
        
        Args:
            y (np.ndarray): ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr (int): ìƒ˜í”Œ ë ˆì´íŠ¸
            
        Returns:
            np.ndarray: RMS ê°’ ì‹œí€€ìŠ¤
        """
        # 0.05ì´ˆë‹¹ ìƒ˜í”Œ ìˆ˜
        samples_per_interval = int(sr * self.analysis_interval)
        
        # ì „ì²´ êµ¬ê°„ ìˆ˜
        num_intervals = len(y) // samples_per_interval
        
        rms_values = []
        
        for i in range(num_intervals):
            start_idx = i * samples_per_interval
            end_idx = start_idx + samples_per_interval
            
            # í•´ë‹¹ êµ¬ê°„ì˜ RMS ê³„ì‚°
            segment = y[start_idx:end_idx]
            rms = np.sqrt(np.mean(segment ** 2))
            rms_values.append(rms)
        
        return np.array(rms_values)
    
    def _extract_vad_sequence(self, y: np.ndarray, sr: int) -> np.ndarray:
        """
        VAD ì‹œí€€ìŠ¤ ì¶”ì¶œ (WebRTC VAD ì‚¬ìš©)
        
        Args:
            y (np.ndarray): ì˜¤ë””ì˜¤ ì‹ í˜¸ (16kHz)
            sr (int): ìƒ˜í”Œ ë ˆì´íŠ¸ (16000ì´ì–´ì•¼ í•¨)
            
        Returns:
            np.ndarray: VAD ì‹œí€€ìŠ¤ (0/1 ë°°ì—´)
        """
        if sr != 16000:
            raise ValueError(f"VADëŠ” 16kHzë§Œ ì§€ì›í•©ë‹ˆë‹¤. í˜„ìž¬: {sr}Hz")
        
        try:
            # 10ms ë‹¨ìœ„ë¡œ VAD ì²˜ë¦¬
            vad_results = []
            
            for i in range(0, len(y) - self.vad_frame_size, self.vad_frame_size):
                frame = y[i:i + self.vad_frame_size]
                
                # int16ìœ¼ë¡œ ë³€í™˜ (WebRTC ìš”êµ¬ì‚¬í•­)
                frame_int16 = (frame * 32767).astype(np.int16)
                
                # VAD íŒì •
                try:
                    is_speech = self.vad.is_speech(frame_int16.tobytes(), sr)
                    vad_results.append(1 if is_speech else 0)
                except Exception as e:
                    # VAD ì‹¤íŒ¨ ì‹œ 0ìœ¼ë¡œ ì²˜ë¦¬
                    vad_results.append(0)
            
            # 0.05ì´ˆ ë‹¨ìœ„ë¡œ ì§‘ê³„ (5ê°œ 10ms í”„ë ˆìž„ â†’ ë‹¤ìˆ˜ê²°)
            aggregated_vad = []
            for i in range(0, len(vad_results), self.vad_aggregation_frames):
                window = vad_results[i:i + self.vad_aggregation_frames]
                
                # ì„¤ì •ëœ ìž„ê³„ê°’ ì´ìƒì´ë©´ ë°œí™”ë¡œ íŒì •
                speech_count = sum(window)
                is_speech = speech_count >= self.vad_majority_threshold
                aggregated_vad.append(1 if is_speech else 0)
            
            return np.array(aggregated_vad)
            
        except Exception as e:
            self.logger.error(f"âŒ VAD ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ëª¨ë“  í”„ë ˆìž„ì„ ì¹¨ë¬µìœ¼ë¡œ ì²˜ë¦¬
            num_frames = len(y) // int(sr * self.analysis_interval)
            return np.zeros(num_frames, dtype=int)
    
    def _calculate_vad_statistics(self, vad_sequence: np.ndarray) -> Dict:
        """VAD í†µê³„ ê³„ì‚°"""
        if len(vad_sequence) == 0:
            return {
                'voice_activity_ratio': 0.0,
                'silence_ratio': 1.0,
                'speech_burst_count': 0,
                'silence_burst_count': 0,
                'max_speech_duration': 0.0,
                'max_silence_duration': 0.0,
                'avg_speech_duration': 0.0,
                'avg_silence_duration': 0.0
            }
        
        # ê¸°ë³¸ ë¹„ìœ¨
        voice_ratio = float(np.mean(vad_sequence))
        silence_ratio = 1.0 - voice_ratio
        
        # ì—°ì† êµ¬ê°„ ë¶„ì„
        speech_bursts = []
        silence_bursts = []
        
        current_state = vad_sequence[0]
        current_duration = 1
        
        for i in range(1, len(vad_sequence)):
            if vad_sequence[i] == current_state:
                current_duration += 1
            else:
                # ìƒíƒœ ë³€í™”
                duration_seconds = current_duration * self.analysis_interval
                
                if current_state == 1:
                    speech_bursts.append(duration_seconds)
                else:
                    silence_bursts.append(duration_seconds)
                
                current_state = vad_sequence[i]
                current_duration = 1
        
        # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
        duration_seconds = current_duration * self.analysis_interval
        if current_state == 1:
            speech_bursts.append(duration_seconds)
        else:
            silence_bursts.append(duration_seconds)
        
        return {
            'voice_activity_ratio': voice_ratio,
            'silence_ratio': silence_ratio,
            'speech_burst_count': len(speech_bursts),
            'silence_burst_count': len(silence_bursts),
            'max_speech_duration': float(max(speech_bursts)) if speech_bursts else 0.0,
            'max_silence_duration': float(max(silence_bursts)) if silence_bursts else 0.0,
            'avg_speech_duration': float(np.mean(speech_bursts)) if speech_bursts else 0.0,
            'avg_silence_duration': float(np.mean(silence_bursts)) if silence_bursts else 0.0
        }
    
    def _save_to_hdf5(self, result: Dict) -> str:
        """
        ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ HDF5 íŒŒì¼ë¡œ ì €ìž¥ (VAD í¬í•¨)
        
        Args:
            result (Dict): ì „ì²˜ë¦¬ ê²°ê³¼
            
        Returns:
            str: ì €ìž¥ëœ HDF5 íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_name = result['video_name'].replace('*', '_').replace(' ', '_')
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            hdf5_filename = f"audio_seq_{safe_name}_{timestamp}.h5"
            hdf5_path = os.path.join(self.audio_sequence_dir, hdf5_filename)
            
            with h5py.File(hdf5_path, 'w') as f:
                # ë©”íƒ€ë°ì´í„°
                f.attrs['video_name'] = result['video_name']
                f.attrs['video_path'] = result['video_path']
                f.attrs['duration'] = result['duration']
                f.attrs['sample_rate'] = result['sample_rate']
                f.attrs['analysis_interval'] = result['analysis_interval']
                f.attrs['total_frames'] = result['metadata']['total_frames']
                f.attrs['frames_per_second'] = result['metadata']['frames_per_second']
                f.attrs['processed_at'] = result['metadata']['processed_at']
                
                # VAD ì„¤ì • ë©”íƒ€ë°ì´í„° ì¶”ê°€
                f.attrs['vad_sensitivity'] = self.vad_sensitivity
                f.attrs['vad_frame_duration'] = self.vad_frame_duration
                f.attrs['vad_aggregation_frames'] = self.vad_aggregation_frames
                f.attrs['vad_majority_threshold'] = self.vad_majority_threshold
                
                # VAD í†µê³„
                vad_stats = result['metadata']['vad_statistics']
                for key, value in vad_stats.items():
                    f.attrs[f'vad_{key}'] = value
                
                # ì‹œí€€ìŠ¤ ë°ì´í„° (ì••ì¶• ì—†ìŒ)
                sequences_group = f.create_group('sequences')
                sequences_group.create_dataset('rms_values', 
                                             data=result['sequences']['rms_values'])
                sequences_group.create_dataset('vad_labels', 
                                             data=result['sequences']['vad_labels'])
                sequences_group.create_dataset('timestamps', 
                                             data=result['sequences']['timestamps'])
            
            return hdf5_path
            
        except Exception as e:
            self.logger.error(f"âŒ HDF5 ì €ìž¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _save_audio_statistics(self, result: Dict):
        """ì˜¤ë””ì˜¤ í†µê³„ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ìž¥"""
        try:
            video_name = result['video_name']
            stats_filename = f"audio_stats_{video_name}.txt"
            stats_path = os.path.join(self.audio_sequence_dir, stats_filename)
            
            vad_stats = result['metadata']['vad_statistics']
            
            with open(stats_path, 'w', encoding='utf-8') as f:
                f.write(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ í†µê³„ ë³´ê³ ì„œ\n")
                f.write(f"{'='*50}\n")
                f.write(f"ì˜ìƒ: {video_name}\n")
                f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write(f"ðŸ“Š ê¸°ë³¸ ì •ë³´\n")
                f.write(f"â”œâ”€ ê¸¸ì´: {result['duration']:.1f}ì´ˆ ({result['duration']/60:.1f}ë¶„)\n")
                f.write(f"â”œâ”€ ìƒ˜í”Œë ˆì´íŠ¸: {result['sample_rate']}Hz\n")
                f.write(f"â”œâ”€ ë¶„ì„ ê°„ê²©: {result['analysis_interval']}ì´ˆ\n")
                f.write(f"â””â”€ ì´ í”„ë ˆìž„: {result['metadata']['total_frames']}ê°œ\n\n")
                
                f.write(f"ðŸŽ™ï¸ VAD í†µê³„\n")
                f.write(f"â”œâ”€ ë°œí™” ë¹„ìœ¨: {vad_stats['voice_activity_ratio']:.1%}\n")
                f.write(f"â”œâ”€ ì¹¨ë¬µ ë¹„ìœ¨: {vad_stats['silence_ratio']:.1%}\n")
                f.write(f"â”œâ”€ ë°œí™” êµ¬ê°„ ìˆ˜: {vad_stats['speech_burst_count']}ê°œ\n")
                f.write(f"â”œâ”€ ì¹¨ë¬µ êµ¬ê°„ ìˆ˜: {vad_stats['silence_burst_count']}ê°œ\n")
                f.write(f"â”œâ”€ ìµœëŒ€ ì—°ì† ë°œí™”: {vad_stats['max_speech_duration']:.1f}ì´ˆ\n")
                f.write(f"â”œâ”€ ìµœëŒ€ ì—°ì† ì¹¨ë¬µ: {vad_stats['max_silence_duration']:.1f}ì´ˆ\n")
                f.write(f"â”œâ”€ í‰ê·  ë°œí™” ê¸¸ì´: {vad_stats['avg_speech_duration']:.1f}ì´ˆ\n")
                f.write(f"â””â”€ í‰ê·  ì¹¨ë¬µ ê¸¸ì´: {vad_stats['avg_silence_duration']:.1f}ì´ˆ\n\n")
                
                f.write(f"âš™ï¸ VAD ì„¤ì •\n")
                f.write(f"â”œâ”€ ë¯¼ê°ë„: {self.vad_sensitivity}\n")
                f.write(f"â”œâ”€ í”„ë ˆìž„ ê¸¸ì´: {self.vad_frame_duration}ms\n")
                f.write(f"â”œâ”€ ì§‘ê³„ í”„ë ˆìž„: {self.vad_aggregation_frames}ê°œ\n")
                f.write(f"â””â”€ ë‹¤ìˆ˜ê²° ìž„ê³„ê°’: {self.vad_majority_threshold}ê°œ\n")
            
            self.logger.info(f"ðŸ“„ ì˜¤ë””ì˜¤ í†µê³„ íŒŒì¼ ì €ìž¥: {stats_path}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í†µê³„ íŒŒì¼ ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    def load_from_hdf5(self, hdf5_path: str) -> Optional[Dict]:
        """
        HDF5 íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ë¡œë“œ (VAD í¬í•¨)
        
        Args:
            hdf5_path (str): HDF5 íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ë¡œë“œëœ ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ ë°ì´í„°
        """
        try:
            with h5py.File(hdf5_path, 'r') as f:
                result = {
                    'video_name': f.attrs['video_name'],
                    'video_path': f.attrs['video_path'],
                    'duration': f.attrs['duration'],
                    'sample_rate': f.attrs['sample_rate'],
                    'analysis_interval': f.attrs['analysis_interval'],
                    'sequences': {
                        'rms_values': f['sequences/rms_values'][:],
                        'vad_labels': f['sequences/vad_labels'][:],
                        'timestamps': f['sequences/timestamps'][:]
                    },
                    'metadata': {
                        'total_frames': f.attrs['total_frames'],
                        'frames_per_second': f.attrs['frames_per_second'],
                        'processed_at': f.attrs['processed_at'],
                        'vad_statistics': {}
                    },
                    'hdf5_path': hdf5_path
                }
                
                # VAD í†µê³„ ë¡œë“œ
                for key in f.attrs.keys():
                    if key.startswith('vad_'):
                        stat_key = key[4:]  # 'vad_' ì œê±°
                        result['metadata']['vad_statistics'][stat_key] = f.attrs[key]
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ HDF5 ë¡œë“œ ì‹¤íŒ¨: {hdf5_path} - {e}")
            return None
    
    def get_audio_statistics(self, hdf5_path: str) -> Optional[Dict]:
        """
        ì˜¤ë””ì˜¤ ì‹œí€€ìŠ¤ í†µê³„ ì •ë³´ ê³„ì‚° (VAD í¬í•¨)
        
        Args:
            hdf5_path (str): HDF5 íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: í†µê³„ ì •ë³´
        """
        data = self.load_from_hdf5(hdf5_path)
        if data is None:
            return None
        
        rms_values = data['sequences']['rms_values']
        vad_labels = data['sequences']['vad_labels']
        
        stats = {
            'duration_minutes': data['duration'] / 60,
            'total_frames': len(rms_values),
            'rms_statistics': {
                'mean': float(np.mean(rms_values)),
                'std': float(np.std(rms_values)),
                'min': float(np.min(rms_values)),
                'max': float(np.max(rms_values)),
                'median': float(np.median(rms_values))
            },
            'vad_statistics': data['metadata']['vad_statistics'],
            'activity_analysis': {
                'high_rms_ratio': float(np.sum(rms_values > np.percentile(rms_values, 75)) / len(rms_values)),
                'low_rms_ratio': float(np.sum(rms_values < np.percentile(rms_values, 25)) / len(rms_values)),
                'rms_silence_ratio': float(np.sum(rms_values < 0.01) / len(rms_values)),
                'vad_voice_ratio': float(np.mean(vad_labels)),
                'vad_silence_ratio': float(1 - np.mean(vad_labels))
            }
        }
        
        return stats


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import argparse
    
    # ëª…ë ¹ì¤„ ì¸ìž íŒŒì‹±
    parser = argparse.ArgumentParser(description='ê¸´ ì˜ìƒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (VAD í†µí•©)')
    parser.add_argument('video_path', help='ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--config', default='video_analyzer/configs/inference_config.yaml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # WebRTC VAD ì„¤ì¹˜ í™•ì¸
    try:
        import webrtcvad
    except ImportError:
        print("âŒ webrtcvad ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜ ëª…ë ¹: pip install webrtcvad")
        return
    
    # ì„¤ì • íŒŒì¼ ìƒì„± (ì—†ëŠ” ê²½ìš°)
    config_dir = "video_analyzer/configs"
    os.makedirs(config_dir, exist_ok=True)
    
    if not os.path.exists(args.config):
        # VAD í†µí•© ê¸°ë³¸ ì„¤ì •
        default_config = {
            'audio': {
                'sample_rate': 16000,
                'analysis_interval': 0.05,
                'vad_sensitivity': 2,
                'vad_frame_duration': 10,
                'vad_aggregation_frames': 5,
                'vad_majority_threshold': 3
            },
            'output': {
                'base_dir': 'video_analyzer',
                'preprocessed_dir': 'preprocessed_data',
                'audio_sequence_dir': 'audio_sequences'
            },
            'logging': {
                'level': 'INFO',
                'save_audio_statistics': True
            },
            'debug': {
                'save_vad_debug_info': False
            }
        }
        
        with open(args.config, 'w', encoding='utf-8') as f:
            yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True)
        print(f"âœ… ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±: {args.config}")
    
    # ì „ì²˜ë¦¬ê¸° ì‹¤í–‰
    preprocessor = LongVideoAudioPreprocessor(args.config)
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    result = preprocessor.preprocess_long_video_audio(args.video_path)
    
    if result:
        print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"HDF5 íŒŒì¼: {result['hdf5_path']}")
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        stats = preprocessor.get_audio_statistics(result['hdf5_path'])
        if stats:
            print(f"\nðŸ“Š ì˜¤ë””ì˜¤ í†µê³„:")
            print(f"ê¸¸ì´: {stats['duration_minutes']:.1f}ë¶„")
            print(f"RMS í‰ê· : {stats['rms_statistics']['mean']:.4f}")
            print(f"RMS í‘œì¤€íŽ¸ì°¨: {stats['rms_statistics']['std']:.4f}")
            print(f"ë°œí™” ë¹„ìœ¨: {stats['vad_statistics']['voice_activity_ratio']:.1%}")
            print(f"ì¹¨ë¬µ ë¹„ìœ¨: {stats['vad_statistics']['silence_ratio']:.1%}")
            print(f"ë°œí™” êµ¬ê°„ ìˆ˜: {stats['vad_statistics']['speech_burst_count']}ê°œ")
    else:
        print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨")


if __name__ == "__main__":
    main()