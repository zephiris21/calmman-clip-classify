# 침착맨 AI 재미도 분석 시스템 - 통합 설정 파일 (간소화 버전)
# 전체 파이프라인의 핵심 설정만 관리

# =============================================================================
# 파이프라인 전체 설정
# =============================================================================
pipeline:
  name: "데이터셋 생성 테스트 파이프라인인"
  version: "1.0.0"
  
  # 파이프라인 단계 정의
  steps:
    1: "video_preprocessing"     # 비디오 전처리 (얼굴 탐지 + 감정 분석)
    2: "audio_preprocessing"     # 오디오 전처리 (VAD + RMS)
    3: "tension_calculation"     # 텐션 계산
    4: "emotion_highlights"      # 감정 하이라이트 추출
    5: "angry_classification"    # 킹받는 얼굴 분류
    viz: "visualization"         # 시각화 생성
  
  # 실행 모드
  execution:
    auto_mode: 0                 # 0: 자동 전체 실행, 1: 단계별 실행 (사용자 입력)

optional_steps:
  emotion_highlights: true     # 4단계 실행 여부
  angry_classification: true   # 5단계 실행 여부  
  visualization: true          # 시각화 실행 여부


# =============================================================================
# 데이터셋 생성 설정 (NEW)
# =============================================================================
dataset:
  # 입력 설정
  input_base_dir: "dataset/clips"        # 클립 폴더 경로
  clip_extensions: [".mp4", ".avi", ".mov"]
  label_mapping:
    funny: 1                             # dataset/clips/funny/*.mp4 → label 1
    boring: 0                            # dataset/clips/boring/*.mp4 → label 0
  
   # 최종 데이터셋 저장 (별도 경로)
  dataset_output_dir: "dataset"          # dataset/dataset.h5로 저장
  dataset_name: "chimchakman_funny_v1"   
  hdf5_filename: "dataset.h5"

  # 검증 정책 (엄격한 검증)
  validation:
    min_frames_per_segment: 8            # 구간별 최소 얼굴 프레임 수
    min_clip_duration: 12.0              # 최소 클립 길이 (초)
    max_clip_duration: 60.0              # 최대 클립 길이 (초)
    require_all_segments: true           # 모든 구간이 조건 만족해야 함
  
  # 3가지 실험 설정
  feature_configs:
    config_1:
      name: "4segments_112d"
      segments: 4                        # 4구간 분할
      dimensions: 112                    # 4 × 28차원
      
    config_2:
      name: "3segments_84d" 
      segments: 3                        # 3구간 분할
      dimensions: 84                     # 3 × 28차원

      
    config_3:
      name: "2segments_96d"
      segments: 2                        # 2구간 분할
      dimensions: 96                     # 2 × 48차원 (감정분류 회귀 포함)

  
  # 배치 처리 설정
  batch_processing:
    max_workers: 1                       # 동시 처리 클립 수 (GPU 메모리 고려)
    skip_existing: true                  # 이미 처리된 클립 스킵
  
  # 진행률 추적
  progress:
    show_progress_bar: true              # 간단한 진행률 바 표시
    update_interval: 1                   # 매 파일마다 업데이트
     

# =============================================================================
# 통합 출력 경로 설정
# =============================================================================
output:
  base_dir: "dataset/preprocessed"                    # 프로젝트 루트/dataset/preprocessed
  classification: "classification"       # 썸네일 분류 결과
  highlights: "highlights"               # 감정 하이라이트 이미지
  visualization: "visualization"         # 그래프, 차트들
  logs: "logs"                          # 실행 로그들
  preprocessed_dir: "preprocessed_data"
  video_sequence_dir: "video_sequences"
  audio_sequence_dir: "audio_sequences"
  tension_analysis_dir: "tension_data"
# =============================================================================
# 1단계: 비디오 전처리 설정
# =============================================================================
video:
  # 프레임 처리 설정
  frame_skip: 15                 # 프레임 스킵 (15 = 0.25초 간격)
  extract_emotions: true         # 감정 추출 여부
  save_face_images: true         # 얼굴 이미지 저장 여부
  save_others_faces: false       # 다른 사람 얼굴 저장 안함 (파이프라인용)
  face_images_dir: "debug_faces"    # 얼굴 이미지 저장 폴더
  
  # MTCNN 얼굴 탐지 설정
  mtcnn:
    batch_size: 32               # 배치 크기
    image_size: 224              # 출력 이미지 크기
    margin: 20                   # 얼굴 주변 여백
    prob_threshold: 0.9          # 얼굴 탐지 확률 임계값
    align_faces: false           # 눈 정렬 비활성화 (속도 우선)
  
  # VA 감정 모델 설정
  emotion:
    model_path: 'models/affectnet_emotions/enet_b0_8_va_mtl.pt'
    device: 'cuda'               # 또는 'cpu'
    batch_size: 32
  
  # FaceNet 얼굴 인식 설정
  face_recognition:
    enabled: true
    test_mode: false             # 테스트 모드 비활성화
    embedding_path: 'face_recognition/target_embeddings/chimchakman.npy'
    similarity_threshold: 0.7    # 침착맨 인식 임계값
    batch_size: 32

# =============================================================================
# 2단계: 오디오 전처리 설정
# =============================================================================
audio:
  sample_rate: 16000          # Silero 요구사항에 맞춰 16kHz로 변경
  analysis_interval: 0.05     # 분석 간격 (초) - 0.05초마다 RMS + VAD 계산
  vad_model: "silero"           # NEW: VAD 모델 선택
  vad_confidence_threshold: 0.5 # NEW: Silero 신뢰도 임계값
  compress_segments: false    # 구간 압축 비활성화 (원시 시퀀스 저장)
  output_format: "sequence"   # 출력 형식: sequence (시퀀스) vs features (압축특징)

# 텐션 계산용 추가 설정
  voice_rms_max: 0.2           # Voice RMS 최대값 (정규화용) 오디오 클리핑
  vad_activity_threshold: 0.2  # VAD 활동 임계값

# =============================================================================
# 3단계: 텐션 계산 설정
# =============================================================================
decay:
  decay_rate: 0.95
  silence_3sec_decay: 0.85
  silence_threshold_seconds: 1.0
editing:
  change_threshold: 0.9
  highlight_sensitivity: 1.5
  low_tension_threshold: 3.0
tension:
  arousal_multiplier: 10
  audio_weight: 0.4
  emotion_weight: 0.6
  window_duration: 0.5

# =============================================================================
# 4단계: 감정 하이라이트 추출 설정
# =============================================================================
emotion_highlights:
  # 추출 설정
  top_n_per_emotion: 5           # 각 감정별 상위 N개 추출
  include_emotions:              # 추출할 감정 목록
    - 'Anger'
    - 'Contempt'
    - 'Disgust'
    - 'Fear'
    - 'Happiness'
    - 'Neutral'
    - 'Sadness'
    - 'Surprise'
    - 'Valence'                  # 극값 (절댓값 최대)
    - 'Arousal'                  # 텐션 높은 순간
  
  # 필터링 설정
  min_emotion_threshold: 0.1     # 최소 감정 임계값
  
  # 이미지 설정
  filename_format: 'highlight_{emotion}_{rank:03d}_{timestamp:.1f}s_{value:.3f}.jpg'

# =============================================================================
# 5단계: 썸네일 분류 설정
# =============================================================================
thumbnail_classification:
  # PyTorch 분류 모델 설정
  model_path: "models/enet_b0_imagenet"  # 모델 디렉토리
  device: "cuda"                 # 또는 "cpu"
  
  # 분류 설정
  confidence_threshold:  0.5     # 썸네일용 판정 임계값
  batch_size: 64                 # 분류 배치 크기
  
  # 출력 설정
  filename_format: 'thumbnail_{rank:03d}_{timestamp:.1f}s_conf{confidence:.3f}.jpg'
  max_thumbnails: 20             # 최대 썸네일 저장 수

# =============================================================================
# 시각화 설정
# =============================================================================
visualization:
  # 그래프 설정
  figure_size: [16, 10]          # 그래프 크기
  dpi: 150                       # 해상도
  
  # 텐션 곡선 설정
  tension_curves:
    save_format: 'png'           # 저장 형식
    show_highlights: true        # 하이라이트 포인트 표시
    time_format: 'mm:ss'         # 시간 형식
  
  # 감정 분포 설정
  emotion_distribution:
    save_format: 'png'
    include_va: true             # Valence, Arousal 포함

# =============================================================================
# 로깅 설정
# =============================================================================
logging:
  level: 'INFO'                  # DEBUG, INFO, WARNING, ERROR
  console_output: false           # 콘솔 출력 여부
  file_output: true              # 파일 출력 여부
  log_filename: 'pipeline_{timestamp}.log'
  save_detailed_log: true